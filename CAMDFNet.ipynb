{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T09:29:12.683015Z",
     "iopub.status.busy": "2026-02-11T09:29:12.682720Z",
     "iopub.status.idle": "2026-02-11T09:29:12.686634Z",
     "shell.execute_reply": "2026-02-11T09:29:12.686116Z",
     "shell.execute_reply.started": "2026-02-11T09:29:12.682986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install SAM\n",
    "#!pip install segment-anything\n",
    "\n",
    "#!pip install git+https://github.com/ChaoningZhang/MobileSAM.git\n",
    "# Download the weights (only 40MB)\n",
    "#!wget https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/weights/mobile_sam.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CAMDF-Net: Context-Aware Multi-Domain Fusion Network\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from scipy.ndimage import uniform_filter\n",
    "from scipy import stats as scipy_stats\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SYSTEM\n",
    "# ============================================================================\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    \"\"\"Dataset configuration with defaults\"\"\"\n",
    "    data_root: str = \"/kaggle/input/plantvillage-dataset/color\"\n",
    "    train_ratio: float = 0.8\n",
    "    val_ratio: float = 0.1\n",
    "    test_ratio: float = 0.1\n",
    "    batch_size: int = 16  # Increased from 1 to avoid batch norm issues\n",
    "    num_workers: int = 4\n",
    "    pin_memory: bool = True\n",
    "    mask_method: str = \"ensemble\"\n",
    "    augment: bool = True\n",
    "    image_size: int = 512\n",
    "    use_advanced_augmentation: bool = True\n",
    "    augment_prob: float = 0.5\n",
    "    color_jitter_brightness: float = 0.3\n",
    "    color_jitter_contrast: float = 0.3\n",
    "    color_jitter_saturation: float = 0.3\n",
    "    color_jitter_hue: float = 0.15\n",
    "    rotation_degrees: int = 30\n",
    "    use_tta: bool = True\n",
    "    tta_transforms: int = 5\n",
    "    preserve_original_size_eval: bool = True\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Model architecture configuration\"\"\"\n",
    "    name: str = \"camdfnet_base\"\n",
    "    num_classes: int = None  # Will be set automatically from dataset\n",
    "    hidden_dim: int = 768\n",
    "    use_fpn: bool = True\n",
    "    use_se: bool = True\n",
    "    use_sarm: bool = True\n",
    "    dropout_rate: float = 0.1\n",
    "    pretrained: bool = True\n",
    "    return_attention_maps: bool = True\n",
    "    save_all_activations: bool = True\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training hyperparameters\"\"\"\n",
    "    epochs: int = 200\n",
    "    learning_rate: float = 1e-4\n",
    "    weight_decay: float = 1e-5\n",
    "    optimizer: str = \"adamw\"\n",
    "    scheduler: str = \"cosine\"\n",
    "    warmup_epochs: int = 10\n",
    "    gradient_clip: float = 1.0\n",
    "    early_stopping_patience: int = 50\n",
    "    mixed_precision: bool = True\n",
    "    use_mixup: bool = True\n",
    "    mixup_alpha: float = 0.2\n",
    "    use_cutmix: bool = True\n",
    "    cutmix_alpha: float = 1.0\n",
    "    augmentation_prob: float = 0.5\n",
    "    split: str = 'test'\n",
    "\n",
    "@dataclass\n",
    "class LossConfig:\n",
    "    \"\"\"Loss function configuration\"\"\"\n",
    "    lambda_dice: float = 1.0\n",
    "    lambda_bce: float = 1.0\n",
    "    lambda_cls: float = 1.0\n",
    "    lambda_mask_reg: float = 0.5\n",
    "    lambda_aux: float = 0.5\n",
    "    use_focal: bool = True\n",
    "    focal_alpha: float = 0.25\n",
    "    focal_gamma: float = 2.0\n",
    "    use_class_weights: bool = True\n",
    "    label_smoothing: float = 0.2\n",
    "\n",
    "@dataclass\n",
    "class SystemConfig:\n",
    "    \"\"\"System-level configuration\"\"\"\n",
    "    device: str = \"cuda\"\n",
    "    seed: int = 42\n",
    "    checkpoint_dir: str = \"./runnings\"\n",
    "    log_dir: str = \"./logs\"\n",
    "    output_dir: str = \"./results\"\n",
    "    save_frequency: int = 25\n",
    "    verbose: bool = True\n",
    "    experiment_name: str = \"camdfnet\"\n",
    "    save_all_intermediates: bool = True\n",
    "\n",
    "@dataclass\n",
    "class CAMDFNetConfig:\n",
    "    \"\"\"Complete system configuration\"\"\"\n",
    "    dataset: DatasetConfig = field(default_factory=DatasetConfig)\n",
    "    model: ModelConfig = field(default_factory=ModelConfig)\n",
    "    training: TrainingConfig = field(default_factory=TrainingConfig)\n",
    "    loss: LossConfig = field(default_factory=LossConfig)\n",
    "    system: SystemConfig = field(default_factory=SystemConfig)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_yaml(cls, path: str) -> 'CAMDFNetConfig':\n",
    "        with open(path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        return cls(\n",
    "            dataset=DatasetConfig(**data.get('dataset', {})),\n",
    "            model=ModelConfig(**data.get('model', {})),\n",
    "            training=TrainingConfig(**data.get('training', {})),\n",
    "            loss=LossConfig(**data.get('loss', {})),\n",
    "            system=SystemConfig(**data.get('system', {}))\n",
    "        )\n",
    "    \n",
    "    def to_yaml(self, path: str):\n",
    "        data = {\n",
    "            'dataset': asdict(self.dataset),\n",
    "            'model': asdict(self.model),\n",
    "            'training': asdict(self.training),\n",
    "            'loss': asdict(self.loss),\n",
    "            'system': asdict(self.system)\n",
    "        }\n",
    "        with open(path, 'w') as f:\n",
    "            yaml.dump(data, f, default_flow_style=False)\n",
    "\n",
    "# ============================================================================\n",
    "# SPP\n",
    "# ============================================================================\n",
    "class SpectralPreProcessor(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3, freq_ratios: List[float] = [0.2, 0.5, 1.0]):\n",
    "        super().__init__()\n",
    "        self.ratios = freq_ratios\n",
    "        self.filters = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(1, in_channels, 1, 1, dtype=torch.complex64))\n",
    "            for _ in freq_ratios\n",
    "        ])\n",
    "        for f in self.filters:\n",
    "            nn.init.normal_(f.real, mean=1.0, std=0.01)\n",
    "            nn.init.normal_(f.imag, mean=0.0, std=0.01)\n",
    "        self.activations = {}\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, c, h, w = x.shape\n",
    "        x_fft = torch.fft.rfft2(x, norm='ortho')\n",
    "        out_spatial = torch.zeros_like(x)\n",
    "        for i, ratio in enumerate(self.ratios):\n",
    "            h_lim = max(1, int(x_fft.shape[2] * ratio))\n",
    "            w_lim = max(1, int(x_fft.shape[3] * ratio))\n",
    "            mask = torch.zeros_like(x_fft)\n",
    "            mask[:, :, :h_lim, :w_lim] = x_fft[:, :, :h_lim, :w_lim]\n",
    "            out_spatial += torch.fft.irfft2(mask * self.filters[i], s=(h, w), norm='ortho')\n",
    "        \n",
    "        self.activations['spectral_output'] = out_spatial.detach()\n",
    "        return out_spatial / len(self.ratios)\n",
    "\n",
    "class PyramidPoolingModule(nn.Module):\n",
    "    def __init__(self, in_channels: int, pool_sizes: List[int] = [1, 2, 3, 6]):\n",
    "        super().__init__()\n",
    "        out_channels = in_channels // len(pool_sizes)\n",
    "        self.stages = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(size),\n",
    "                nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for size in pool_sizes\n",
    "        ])\n",
    "        self.activations = {}\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h, w = x.shape[2:]\n",
    "        pyramids = [x]\n",
    "        for i, stage in enumerate(self.stages):\n",
    "            pooled = stage(x)\n",
    "            pyramids.append(F.interpolate(pooled, size=(h, w), mode='bilinear', align_corners=True))\n",
    "            self.activations[f'pool_stage_{i}'] = pooled.detach()\n",
    "        \n",
    "        output = torch.cat(pyramids, dim=1)\n",
    "        self.activations['pyramid_output'] = output.detach()\n",
    "        return output\n",
    "\n",
    "class AttentionRefinementModule(nn.Module):\n",
    "    \"\"\"Refine segmentation masks using attention\"\"\"\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 2, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels // 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels // 2, 1, 1)\n",
    "        self.activations = {}\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        attention = torch.sigmoid(self.conv2(x1))\n",
    "        \n",
    "        self.activations['attention_input'] = x.detach()\n",
    "        self.activations['attention_output'] = attention.detach()\n",
    "        \n",
    "        return attention\n",
    "\n",
    "class CAMDFNet(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.activations = {}\n",
    "        self.gradients = {}\n",
    "        is_large = \"large\" in config.name.lower()\n",
    "        \n",
    "        if is_large:\n",
    "            self.vit = models.vit_l_16(weights=models.ViT_L_16_Weights.IMAGENET1K_V1)\n",
    "            self.hidden_dim, self.num_heads = 1024, 16\n",
    "            eff = models.efficientnet_b7(weights=models.EfficientNet_B7_Weights.IMAGENET1K_V1)\n",
    "            cnn_ch = 224\n",
    "        else:\n",
    "            self.vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "            self.hidden_dim, self.num_heads = 768, 12\n",
    "            eff = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "            cnn_ch = 160\n",
    "        \n",
    "        self.vit_layers = self.vit.encoder.layers\n",
    "        self.spectral_pre = SpectralPreProcessor()\n",
    "        self.cnn_backbone = nn.Sequential(*list(eff.features.children())[:6])\n",
    "        self.proj2 = nn.Conv2d(cnn_ch, self.hidden_dim, 1)\n",
    "        self.pyramid_pool = PyramidPoolingModule(self.hidden_dim)\n",
    "        \n",
    "        self.attention_refine = AttentionRefinementModule(self.hidden_dim * 2)\n",
    "        \n",
    "        # Segmentation head\n",
    "        self.segmentation_head = nn.Sequential(\n",
    "            nn.Conv2d(self.hidden_dim * 2, 256, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.BatchNorm2d(16), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.cross_attention = nn.MultiheadAttention(self.hidden_dim, num_heads=self.num_heads, batch_first=False)\n",
    "        \n",
    "        # Classifier - IMPORTANT: num_classes is set automatically from dataset\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
    "            nn.Linear(self.hidden_dim, config.num_classes)\n",
    "        )\n",
    "        \n",
    "        self.uncertainty_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
    "            nn.Linear(self.hidden_dim, 1), nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Register hooks for all intermediate layers\n",
    "        self._register_all_hooks()\n",
    "    \n",
    "    def _register_all_hooks(self):\n",
    "        def save_activation(name):\n",
    "            def hook(module, input, output):\n",
    "                if isinstance(output, tuple):\n",
    "                    if len(output) == 2:\n",
    "                        if output[0] is not None and hasattr(output[0], 'detach'):\n",
    "                            self.activations[name + '_output'] = output[0].detach()\n",
    "                        if output[1] is not None and hasattr(output[1], 'detach'):\n",
    "                            self.activations[name + '_weights'] = output[1].detach()\n",
    "                    else:\n",
    "                        for i, out in enumerate(output):\n",
    "                            if out is not None and hasattr(out, 'detach'):\n",
    "                                self.activations[f'{name}_tuple_{i}'] = out.detach()\n",
    "                else:\n",
    "                    if output is not None and hasattr(output, 'detach'):\n",
    "                        self.activations[name] = output.detach()\n",
    "            return hook\n",
    "        \n",
    "        def save_gradient(name):\n",
    "            def hook(module, grad_input, grad_output):\n",
    "                if isinstance(grad_output, tuple):\n",
    "                    if len(grad_output) > 0 and grad_output[0] is not None:\n",
    "                        self.gradients[name] = grad_output[0].detach()\n",
    "                elif grad_output is not None and hasattr(grad_output, 'detach'):\n",
    "                    self.gradients[name] = grad_output.detach()\n",
    "            return hook\n",
    "        \n",
    "        self.spectral_pre.register_forward_hook(save_activation('spectral_pre'))\n",
    "        \n",
    "        for i, layer in enumerate(self.cnn_backbone):\n",
    "            layer.register_forward_hook(save_activation(f'cnn_layer_{i}'))\n",
    "        \n",
    "        self.proj2.register_forward_hook(save_activation('proj2'))\n",
    "        self.pyramid_pool.register_forward_hook(save_activation('pyramid_pool'))\n",
    "        self.attention_refine.register_forward_hook(save_activation('attention_refine'))\n",
    "        \n",
    "        for i, layer in enumerate(self.segmentation_head):\n",
    "            layer.register_forward_hook(save_activation(f'seg_layer_{i}'))\n",
    "        \n",
    "        self.cross_attention.register_forward_hook(save_activation('cross_attention'))\n",
    "        self.classifier.register_forward_hook(save_activation('classifier'))\n",
    "        self.uncertainty_head.register_forward_hook(save_activation('uncertainty_head'))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        b, _, h, w = x.shape\n",
    "        \n",
    "        self.activations.clear()\n",
    "        self.activations['input'] = x.detach()\n",
    "        \n",
    "        x_res = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=True)\n",
    "        x_spec = self.spectral_pre(x_res)\n",
    "        \n",
    "        v = self.vit\n",
    "        x_v = v._process_input(x_spec)\n",
    "        n = x_v.shape[0]\n",
    "        cls_token = v.class_token.expand(n, -1, -1)\n",
    "        x_v = torch.cat((cls_token, x_v), dim=1)\n",
    "        x_v = v.encoder(x_v)\n",
    "        \n",
    "        vit_spatial = x_v[:, 1:].transpose(1, 2).reshape(b, self.hidden_dim, 14, 14)\n",
    "        self.activations['vit_spatial'] = vit_spatial.detach()\n",
    "        self.activations['vit_sequence'] = x_v.detach()\n",
    "        \n",
    "        # Get pyramid pooled features\n",
    "        pooled_features = self.pyramid_pool(vit_spatial)\n",
    "        \n",
    "        # Get attention weights for mask refinement\n",
    "        attention_weights = self.attention_refine(pooled_features)\n",
    "        \n",
    "        # Generate mask with attention refinement\n",
    "        mask_logits = self.segmentation_head(pooled_features)\n",
    "        attention_weights_upsampled = F.interpolate(attention_weights, size=(224, 224), mode='bilinear', align_corners=True)\n",
    "        refined_mask = mask_logits * attention_weights_upsampled\n",
    "        self.activations['mask_logits'] = mask_logits.detach()\n",
    "        self.activations['refined_mask'] = refined_mask.detach()\n",
    "        \n",
    "        gated_x = x_spec * (0.5 + 0.5 * torch.sigmoid(refined_mask))\n",
    "        self.activations['gated_x'] = gated_x.detach()\n",
    "        \n",
    "        cnn_features = self.cnn_backbone(gated_x)\n",
    "        self.activations['cnn_features_raw'] = cnn_features.detach()\n",
    "        \n",
    "        cnn_aligned = F.interpolate(self.proj2(cnn_features), size=(14, 14), mode='bilinear', align_corners=True)\n",
    "        self.activations['cnn_aligned'] = cnn_aligned.detach()\n",
    "        \n",
    "        cnn_seq = cnn_aligned.flatten(2).permute(2, 0, 1)\n",
    "        vit_seq = x_v.permute(1, 0, 2)\n",
    "        \n",
    "        fused_seq, cross_weights = self.cross_attention(cnn_seq, vit_seq, vit_seq, need_weights=True)\n",
    "        \n",
    "        fused_feat = fused_seq.permute(1, 2, 0).reshape(b, self.hidden_dim, 14, 14)\n",
    "        self.activations['fused_features'] = fused_feat.detach()\n",
    "        \n",
    "        cls_logits = self.classifier(fused_feat)\n",
    "        uncertainty = self.uncertainty_head(fused_feat)\n",
    "        mask_upscaled = F.interpolate(refined_mask, size=(h, w), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.activations['cls_logits'] = cls_logits.detach()\n",
    "        self.activations['uncertainty'] = uncertainty.detach()\n",
    "        self.activations['final_mask'] = mask_upscaled.detach()\n",
    "        \n",
    "        return {\n",
    "            'logits': cls_logits,\n",
    "            'mask': mask_upscaled,\n",
    "            'uncertainty': uncertainty,\n",
    "            'cross_attention_weights': cross_weights,\n",
    "            'spectral_image': x_spec,\n",
    "            'vit_features': vit_spatial,\n",
    "            'cnn_features': cnn_aligned,\n",
    "            'fused_features': fused_feat,\n",
    "            'vit_sequence': x_v,\n",
    "            'attention_weights': attention_weights\n",
    "        }\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_vit_self_attention(self, x: torch.Tensor, \n",
    "                               layer_indices: List[int] = None,\n",
    "                               return_all_heads: bool = False) -> Dict[str, Any]:\n",
    "        self.eval()\n",
    "        b, _, h, w = x.shape\n",
    "        \n",
    "        x_res = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=True)\n",
    "        x_spec = self.spectral_pre(x_res)\n",
    "        v = self.vit\n",
    "        \n",
    "        x_v = v._process_input(x_spec)\n",
    "        n = x_v.shape[0]\n",
    "        cls_token = v.class_token.expand(n, -1, -1)\n",
    "        x_v = torch.cat((cls_token, x_v), dim=1)\n",
    "        x_v = x_v + v.encoder.pos_embedding\n",
    "        \n",
    "        if layer_indices is None:\n",
    "            layer_indices = list(range(len(v.encoder.layers)))\n",
    "        \n",
    "        attention_maps = {}\n",
    "        \n",
    "        current_x = x_v\n",
    "        for idx, layer in enumerate(v.encoder.layers):\n",
    "            if idx in layer_indices:\n",
    "                norm_x = layer.ln_1(current_x)\n",
    "                qkv = F.linear(norm_x, layer.self_attention.in_proj_weight, \n",
    "                              layer.self_attention.in_proj_bias)\n",
    "                \n",
    "                head_dim = self.hidden_dim // self.num_heads\n",
    "                qkv = qkv.reshape(b, -1, 3, self.num_heads, head_dim).permute(2, 0, 3, 1, 4)\n",
    "                q, k, v_ = qkv[0], qkv[1], qkv[2]\n",
    "                \n",
    "                attn = (q @ k.transpose(-2, -1)) * (head_dim ** -0.5)\n",
    "                attn = attn.softmax(dim=-1)\n",
    "                \n",
    "                if return_all_heads:\n",
    "                    head_attentions = {}\n",
    "                    for head_idx in range(self.num_heads):\n",
    "                        cls_attn_head = attn[:, head_idx, 0, 1:]\n",
    "                        cls_attn_map = cls_attn_head.reshape(b, 14, 14)\n",
    "                        \n",
    "                        map_min = cls_attn_map.amin(dim=(1, 2), keepdim=True)\n",
    "                        map_max = cls_attn_map.amax(dim=(1, 2), keepdim=True)\n",
    "                        cls_attn_map = (cls_attn_map - map_min) / (map_max - map_min + 1e-8)\n",
    "                        \n",
    "                        head_attentions[f'head_{head_idx}'] = cls_attn_map\n",
    "                    \n",
    "                    attention_maps[f'layer_{idx}'] = head_attentions\n",
    "                else:\n",
    "                    attn_avg = attn.mean(dim=1)\n",
    "                    cls_attn = attn_avg[:, 0, 1:]\n",
    "                    cls_attn_map = cls_attn.reshape(b, 14, 14)\n",
    "                    \n",
    "                    map_min = cls_attn_map.amin(dim=(1, 2), keepdim=True)\n",
    "                    map_max = cls_attn_map.amax(dim=(1, 2), keepdim=True)\n",
    "                    cls_attn_map = (cls_attn_map - map_min) / (map_max - map_min + 1e-8)\n",
    "                    \n",
    "                    attention_maps[f'layer_{idx}'] = cls_attn_map\n",
    "            \n",
    "            current_x = layer(current_x)\n",
    "        \n",
    "        return attention_maps\n",
    "    \n",
    "    def get_all_activations(self) -> Dict[str, torch.Tensor]:\n",
    "        return self.activations.copy()\n",
    "    \n",
    "    def get_all_gradients(self) -> Dict[str, torch.Tensor]:\n",
    "        return self.gradients.copy()\n",
    "\n",
    "# ============================================================================\n",
    "# MASK GENERATOR\n",
    "# ============================================================================\n",
    "class MaskGenerator:\n",
    "    @staticmethod\n",
    "    def generate_hsv_disease_mask(image: np.ndarray) -> np.ndarray:\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        lower_brown = np.array([10, 30, 20])\n",
    "        upper_brown = np.array([30, 180, 150])\n",
    "        brown_mask = cv2.inRange(hsv, lower_brown, upper_brown)\n",
    "        \n",
    "        lower_yellow = np.array([20, 40, 100])\n",
    "        upper_yellow = np.array([35, 255, 255])\n",
    "        yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "        \n",
    "        lower_dark = np.array([0, 0, 0])\n",
    "        upper_dark = np.array([180, 255, 80])\n",
    "        dark_mask = cv2.inRange(hsv, lower_dark, upper_dark)\n",
    "        \n",
    "        disease_mask = cv2.bitwise_or(brown_mask, yellow_mask)\n",
    "        disease_mask = cv2.bitwise_or(disease_mask, dark_mask)\n",
    "        \n",
    "        return disease_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_lab_disease_mask(image: np.ndarray) -> np.ndarray:\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "        \n",
    "        _, a_thresh = cv2.threshold(a_channel, 135, 255, cv2.THRESH_BINARY)\n",
    "        _, b_thresh = cv2.threshold(b_channel, 135, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        lab_mask = cv2.bitwise_or(a_thresh, b_thresh)\n",
    "        \n",
    "        return lab_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_edge_disease_mask(image: np.ndarray) -> np.ndarray:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        bilateral = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "        \n",
    "        edges = cv2.Canny(bilateral, 30, 100)\n",
    "        \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "        \n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        edge_mask = np.zeros_like(gray)\n",
    "        cv2.drawContours(edge_mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "        \n",
    "        return edge_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_texture_disease_mask(image: np.ndarray) -> np.ndarray:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        gabor_responses = []\n",
    "        for theta in [0, 45, 90, 135]:\n",
    "            kernel = cv2.getGaborKernel((21, 21), 5, np.deg2rad(theta), 10, 0.5, 0, ktype=cv2.CV_32F)\n",
    "            filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)\n",
    "            gabor_responses.append(filtered)\n",
    "        \n",
    "        gabor_combined = np.max(np.stack(gabor_responses), axis=0).astype(np.uint8)\n",
    "        \n",
    "        _, texture_mask = cv2.threshold(gabor_combined, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        return texture_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_statistical_mask(image: np.ndarray) -> np.ndarray:\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        \n",
    "        masks = []\n",
    "        for channel in cv2.split(lab):\n",
    "            local_mean = uniform_filter(channel.astype(float), size=15)\n",
    "            local_var = uniform_filter(channel.astype(float)**2, size=15) - local_mean**2\n",
    "            local_var = np.maximum(local_var, 0)\n",
    "            \n",
    "            var_range = local_var.max() - local_var.min()\n",
    "            if var_range < 1e-8:\n",
    "                var_norm = np.zeros_like(local_var, dtype=np.uint8)\n",
    "            else:\n",
    "                var_norm = ((local_var - local_var.min()) / (var_range + 1e-8) * 255).astype(np.uint8)\n",
    "            _, var_mask = cv2.threshold(var_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            masks.append(var_mask)\n",
    "        \n",
    "        stat_mask = cv2.bitwise_or(masks[0], masks[1])\n",
    "        stat_mask = cv2.bitwise_or(stat_mask, masks[2])\n",
    "        \n",
    "        return stat_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def ensemble_mask_generation(image: np.ndarray, methods: Optional[List[str]] = None) -> np.ndarray:\n",
    "        if methods is None:\n",
    "            methods = ['hsv', 'lab', 'edge', 'texture', 'statistical']\n",
    "        \n",
    "        masks = []\n",
    "        \n",
    "        if 'hsv' in methods:\n",
    "            masks.append(MaskGenerator.generate_hsv_disease_mask(image))\n",
    "        if 'lab' in methods:\n",
    "            masks.append(MaskGenerator.generate_lab_disease_mask(image))\n",
    "        if 'edge' in methods:\n",
    "            masks.append(MaskGenerator.generate_edge_disease_mask(image))\n",
    "        if 'texture' in methods:\n",
    "            masks.append(MaskGenerator.generate_texture_disease_mask(image))\n",
    "        if 'statistical' in methods:\n",
    "            masks.append(MaskGenerator.generate_statistical_mask(image))\n",
    "        \n",
    "        mask_stack = np.stack([m / 255.0 for m in masks], axis=0)\n",
    "        vote_mask = (mask_stack.mean(axis=0) > 0.5).astype(np.uint8) * 255\n",
    "        \n",
    "        vote_mask = MaskGenerator.post_process_mask(vote_mask, image)\n",
    "        \n",
    "        return vote_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def post_process_mask(mask: np.ndarray, original_image: np.ndarray) -> np.ndarray:\n",
    "        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        kernel_large = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "        \n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_small, iterations=2)\n",
    "        \n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_large, iterations=2)\n",
    "        \n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "        min_size = int((mask.shape[0] * mask.shape[1]) * 0.001)\n",
    "        \n",
    "        filtered_mask = np.zeros_like(mask)\n",
    "        for i in range(1, num_labels):\n",
    "            if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "                filtered_mask[labels == i] = 255\n",
    "        \n",
    "        filtered_mask = cv2.GaussianBlur(filtered_mask, (5, 5), 0)\n",
    "        _, filtered_mask = cv2.threshold(filtered_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        return filtered_mask\n",
    "\n",
    "# ============================================================================\n",
    "# CUSTOM COLLATE FUNCTION\n",
    "# ============================================================================\n",
    "def custom_collate_fn(batch):\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    \n",
    "    mask_shapes = [item[1].shape for item in batch]\n",
    "    all_same_shape = all(s == mask_shapes[0] for s in mask_shapes)\n",
    "    \n",
    "    if all_same_shape:\n",
    "        masks = torch.stack([item[1] for item in batch])\n",
    "    else:\n",
    "        masks = [item[1] for item in batch]\n",
    "    \n",
    "    labels = torch.tensor([item[2] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    original_sizes = [item[3] for item in batch]\n",
    "    \n",
    "    return images, masks, labels, original_sizes\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET WITH IMPROVED MASK GENERATION\n",
    "# ============================================================================\n",
    "class CottonDiseaseDataset(Dataset):\n",
    "    def __init__(self, config, split: str = 'train'):\n",
    "        self.config = config\n",
    "        self.split = split\n",
    "        self.data_root = Path(config.data_root)\n",
    "        self.samples = []\n",
    "        self.classes = sorted([d.name for d in self.data_root.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.mask_generator = MaskGenerator()\n",
    "        print(f\"Classes found: {len(self.classes)}\")\n",
    "        print(f\"Classes: {self.classes}\")\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.data_root / class_name\n",
    "            for img_path in sorted(list(class_dir.glob('*.*')) + list(class_dir.glob('*.png'))):\n",
    "                self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
    "        \n",
    "        print(f\"Total samples: {len(self.samples)}\")\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int, Tuple[int, int]]:\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        original_size = image.size\n",
    "        \n",
    "        image_np = np.array(image)\n",
    "        mask = self.generate_mask(image_np)\n",
    "        \n",
    "        mask_pil = Image.fromarray((mask * 255).astype(np.uint8)).convert('L')\n",
    "        \n",
    "        if self.split == 'train' and getattr(self.config, 'augment', False):\n",
    "            image_transformed, mask_transformed = self.apply_augmentations(image, mask_pil)\n",
    "        else:\n",
    "            image_transformed = transforms.Resize((self.config.image_size, self.config.image_size))(image)\n",
    "            if self.split in ['test', 'val'] and getattr(self.config, 'preserve_original_size_eval', True):\n",
    "                mask_transformed = mask_pil\n",
    "            else:\n",
    "                mask_transformed = transforms.Resize(\n",
    "                    (self.config.image_size, self.config.image_size), \n",
    "                    interpolation=transforms.InterpolationMode.NEAREST\n",
    "                )(mask_pil)\n",
    "        \n",
    "        image_tensor = transforms.ToTensor()(image_transformed)\n",
    "        mask_tensor = transforms.ToTensor()(mask_transformed)\n",
    "        \n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        image_tensor = normalize(image_tensor)\n",
    "        \n",
    "        return image_tensor, mask_tensor, label, original_size\n",
    "\n",
    "    def apply_augmentations(self, image: Image.Image, mask: Image.Image) -> Tuple[Image.Image, Image.Image]:\n",
    "        if random.random() < 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            mask = transforms.functional.hflip(mask)\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            image = transforms.functional.vflip(image)\n",
    "            mask = transforms.functional.vflip(mask)\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            angle = random.uniform(\n",
    "                -getattr(self.config, 'rotation_degrees', 30), \n",
    "                getattr(self.config, 'rotation_degrees', 30)\n",
    "            )\n",
    "            image = transforms.functional.rotate(image, angle, interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "            mask = transforms.functional.rotate(mask, angle, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        \n",
    "        image = transforms.Resize((self.config.image_size, self.config.image_size))(image)\n",
    "        mask = transforms.Resize(\n",
    "            (self.config.image_size, self.config.image_size), \n",
    "            interpolation=transforms.InterpolationMode.NEAREST\n",
    "        )(mask)\n",
    "        \n",
    "        if random.random() < getattr(self.config, 'augment_prob', 0.5) and getattr(self.config, 'use_advanced_augmentation', False):\n",
    "            color_jitter = transforms.ColorJitter(\n",
    "                brightness=getattr(self.config, 'color_jitter_brightness', 0.2),\n",
    "                contrast=getattr(self.config, 'color_jitter_contrast', 0.2),\n",
    "                saturation=getattr(self.config, 'color_jitter_saturation', 0.2),\n",
    "                hue=getattr(self.config, 'color_jitter_hue', 0.1)\n",
    "            )\n",
    "            image = color_jitter(image)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "    def generate_mask(self, image: np.ndarray) -> np.ndarray:\n",
    "        method = getattr(self.config, 'mask_method', 'ensemble')\n",
    "        \n",
    "        if method == 'ensemble':\n",
    "            mask = self.mask_generator.ensemble_mask_generation(image)\n",
    "        elif method == 'hsv':\n",
    "            mask = self.mask_generator.generate_hsv_disease_mask(image)\n",
    "        elif method == 'lab':\n",
    "            mask = self.mask_generator.generate_lab_disease_mask(image)\n",
    "        elif method == 'edge':\n",
    "            mask = self.mask_generator.generate_edge_disease_mask(image)\n",
    "        elif method == 'texture':\n",
    "            mask = self.mask_generator.generate_texture_disease_mask(image)\n",
    "        elif method == 'statistical':\n",
    "            mask = self.mask_generator.generate_statistical_mask(image)\n",
    "        else:\n",
    "            mask = self.mask_generator.ensemble_mask_generation(image)\n",
    "        \n",
    "        if method != 'ensemble':\n",
    "            mask = self.mask_generator.post_process_mask(mask, image)\n",
    "            \n",
    "        return mask.astype(np.float32) / 255.0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "def create_dataloaders(config: CAMDFNetConfig) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    from torch.utils.data import random_split\n",
    "    full_dataset = CottonDiseaseDataset(config.dataset, split=config.training.split)\n",
    "    \n",
    "    # Set num_classes automatically from dataset\n",
    "    config.model.num_classes = len(full_dataset.classes)\n",
    "    print(f\"\\nðŸ“Š Dataset Information:\")\n",
    "    print(f\"  Total samples: {len(full_dataset)}\")\n",
    "    print(f\"  Number of classes: {config.model.num_classes}\")\n",
    "    print(f\"  Classes: {full_dataset.classes}\")\n",
    "    \n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(total_size * config.dataset.train_ratio)\n",
    "    val_size = int(total_size * config.dataset.val_ratio)\n",
    "    test_size = total_size - train_size - val_size\n",
    "    \n",
    "    generator = torch.Generator().manual_seed(config.system.seed)\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
    "    )\n",
    "    \n",
    "    print(f\"  Training samples: {len(train_dataset)}\")\n",
    "    print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"  Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.dataset.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.dataset.num_workers,\n",
    "        pin_memory=config.dataset.pin_memory,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.dataset.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.dataset.num_workers,\n",
    "        pin_memory=config.dataset.pin_memory,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.dataset.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.dataset.num_workers,\n",
    "        pin_memory=config.dataset.pin_memory,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# ============================================================================\n",
    "# AUGMENTATION & LOSS FUNCTIONS\n",
    "# ============================================================================\n",
    "def mixup_data(x: torch.Tensor, y: torch.Tensor, alpha: float = 0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def cutmix_data(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    _, _, H, W = x.shape\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    mixed_x = x.clone()\n",
    "    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor, smooth: float = 1.0) -> torch.Tensor:\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred_flat = pred.view(pred.size(0), -1)\n",
    "        target_flat = target.view(target.size(0), -1)\n",
    "        intersection = (pred_flat * target_flat).sum(dim=1)\n",
    "        union = pred_flat.sum(dim=1) + target_flat.sum(dim=1)\n",
    "        dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "        return 1.0 - dice.mean()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        ce_loss = F.cross_entropy(pred, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "def _prepare_masks_for_loss(mask_pred: torch.Tensor, mask_true, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if isinstance(mask_true, torch.Tensor):\n",
    "        if mask_true.shape[-2:] != mask_pred.shape[-2:]:\n",
    "            mask_true = F.interpolate(mask_true.float(), size=mask_pred.shape[-2:], mode='nearest')\n",
    "        return mask_pred, mask_true.to(device)\n",
    "    elif isinstance(mask_true, list):\n",
    "        resized_masks = []\n",
    "        for m in mask_true:\n",
    "            if isinstance(m, np.ndarray):\n",
    "                m = torch.from_numpy(m).float()\n",
    "            if m.dim() == 2:\n",
    "                m = m.unsqueeze(0).unsqueeze(0)\n",
    "            elif m.dim() == 3:\n",
    "                m = m.unsqueeze(0)\n",
    "            m_resized = F.interpolate(m.float(), size=mask_pred.shape[-2:], mode='nearest')\n",
    "            resized_masks.append(m_resized.squeeze(0))\n",
    "        mask_true_stacked = torch.stack(resized_masks).to(device)\n",
    "        return mask_pred, mask_true_stacked\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected mask_true type: {type(mask_true)}\")\n",
    "\n",
    "class CAMDFNetLoss(nn.Module):\n",
    "    def __init__(self, config: LossConfig, class_weights: Optional[torch.Tensor] = None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.focal_loss = FocalLoss(config.focal_alpha, config.focal_gamma) if config.use_focal else None\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def forward(self, outputs: Dict[str, torch.Tensor], targets: Tuple) -> Dict[str, torch.Tensor]:\n",
    "        images, mask_true, labels = targets[:3]\n",
    "        logits = outputs['logits']\n",
    "        mask_pred = outputs['mask']\n",
    "        uncertainty = outputs['uncertainty']\n",
    "        \n",
    "        device = logits.device\n",
    "        \n",
    "        mask_pred_for_loss, mask_true_for_loss = _prepare_masks_for_loss(mask_pred, mask_true, device)\n",
    "        \n",
    "        if self.config.use_focal and self.focal_loss:\n",
    "            cls_loss = self.focal_loss(logits, labels)\n",
    "        else:\n",
    "            cls_loss = F.cross_entropy(\n",
    "                logits, labels,\n",
    "                weight=self.class_weights,\n",
    "                label_smoothing=self.config.label_smoothing\n",
    "            )\n",
    "        \n",
    "        dice_loss = self.dice_loss(mask_pred_for_loss, mask_true_for_loss)\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(mask_pred_for_loss, mask_true_for_loss)\n",
    "        mask_reg = (torch.sigmoid(mask_pred_for_loss).mean() - 0.5).abs()\n",
    "        aux_loss = torch.tensor(0.0, device=device)\n",
    "        \n",
    "        total_loss = (\n",
    "            self.config.lambda_cls * cls_loss +\n",
    "            self.config.lambda_dice * dice_loss +\n",
    "            self.config.lambda_bce * bce_loss +\n",
    "            self.config.lambda_mask_reg * mask_reg +\n",
    "            self.config.lambda_aux * aux_loss\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'total': total_loss,\n",
    "            'classification': cls_loss,\n",
    "            'dice': dice_loss,\n",
    "            'bce': bce_loss,\n",
    "            'mask_reg': mask_reg,\n",
    "            'auxiliary': aux_loss\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING ENGINE WITH BATCH SIZE HANDLING\n",
    "# ============================================================================\n",
    "class CAMDFNetTrainer:\n",
    "    def __init__(self, config: CAMDFNetConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.system.device if torch.cuda.is_available() else 'cpu')\n",
    "        Path(config.system.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        Path(config.system.log_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nðŸ¤– Initializing CAMDF-Net Trainer\")\n",
    "        print(f\"   Device: {self.device}\")\n",
    "        \n",
    "        # Create dataloaders first to get number of classes\n",
    "        self.train_loader, self.val_loader, self.test_loader = create_dataloaders(config)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Creating model with {config.model.num_classes} classes\")\n",
    "        self.model = CAMDFNet(config.model).to(self.device)\n",
    "        \n",
    "        # Calculate class weights\n",
    "        class_weights = self._calculate_class_weights() if config.loss.use_class_weights else None\n",
    "        if class_weights is not None:\n",
    "            print(f\"   Class weights calculated: {class_weights.cpu().numpy()}\")\n",
    "        \n",
    "        self.criterion = CAMDFNetLoss(config.loss, class_weights)\n",
    "        \n",
    "        if config.training.optimizer == 'adamw':\n",
    "            self.optimizer = optim.AdamW(\n",
    "                self.model.parameters(),\n",
    "                lr=config.training.learning_rate,\n",
    "                weight_decay=config.training.weight_decay\n",
    "            )\n",
    "        elif config.training.optimizer == 'adam':\n",
    "            self.optimizer = optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=config.training.learning_rate,\n",
    "                weight_decay=config.training.weight_decay\n",
    "            )\n",
    "        else:\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=config.training.learning_rate,\n",
    "                momentum=0.9,\n",
    "                weight_decay=config.training.weight_decay\n",
    "            )\n",
    "        \n",
    "        if config.training.scheduler == 'cosine':\n",
    "            self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                self.optimizer, T_0=10, T_mult=2\n",
    "            )\n",
    "        elif config.training.scheduler == 'step':\n",
    "            self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=30, gamma=0.1)\n",
    "        else:\n",
    "            self.scheduler = None\n",
    "        \n",
    "        self.current_epoch = 0\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [], 'val_acc': [], 'train_acc': [],\n",
    "            'val_precision': [], 'val_recall': [], 'val_f1': [], 'val_auc': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "        self.early_stopping_counter = 0\n",
    "        self._resume_from_checkpoint()\n",
    "    \n",
    "    def _resume_from_checkpoint(self):\n",
    "        latest_checkpoint = Path(self.config.system.checkpoint_dir) / 'latest.pth'\n",
    "        if latest_checkpoint.exists():\n",
    "            print(f\"\\nðŸ¤–     Found existing checkpoint: {latest_checkpoint}\")\n",
    "            checkpoint = torch.load(latest_checkpoint, map_location=self.device, weights_only=False)\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            if self.scheduler and 'scheduler_state_dict' in checkpoint:\n",
    "                if checkpoint['scheduler_state_dict'] is not None:\n",
    "                    self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            self.current_epoch = checkpoint['epoch'] + 1\n",
    "            self.best_val_acc = checkpoint.get('best_val_acc', 0.0)\n",
    "            self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "            self.history = checkpoint.get('history', self.history)\n",
    "            self.early_stopping_counter = checkpoint.get('early_stopping_counter', 0)\n",
    "            print(f\"âœ…    Resumed from epoch {self.current_epoch}\")\n",
    "            print(f\"  Best validation accuracy: {self.best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            print(\"\\nðŸ¤–     No checkpoint found. Starting fresh training...\")\n",
    "    \n",
    "    def _calculate_class_weights(self) -> torch.Tensor:\n",
    "        self.config.model.num_classes = len(self.train_loader.dataset.dataset.classes)\n",
    "        class_counts = torch.zeros(self.config.model.num_classes)\n",
    "        dataset = self.train_loader.dataset\n",
    "        \n",
    "        if hasattr(dataset, 'indices'):\n",
    "            base_dataset = dataset.dataset\n",
    "            for idx in dataset.indices:\n",
    "                _, _, label, _ = base_dataset[idx]\n",
    "                class_counts[label] += 1\n",
    "        else:\n",
    "            for i in range(len(dataset)):\n",
    "                _, _, label, _ = dataset[i]\n",
    "                class_counts[label] += 1\n",
    "        \n",
    "        class_counts = class_counts.clamp(min=1)\n",
    "        weights = 1.0 / class_counts\n",
    "        weights = weights / weights.sum() * len(weights)\n",
    "        return weights.to(self.device)\n",
    "    \n",
    "    def train_epoch(self) -> float:\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {self.current_epoch + 1}')\n",
    "        \n",
    "        for images, masks, labels, original_sizes in pbar:\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            \n",
    "            # Skip augmentation if batch size is too small for mixup/cutmix\n",
    "            batch_size = images.size(0)\n",
    "            use_augmentation = (np.random.rand() < self.config.training.augmentation_prob) and (batch_size > 1)\n",
    "            \n",
    "            if self.config.training.use_mixup and use_augmentation and batch_size > 1:\n",
    "                mixed_images, labels_a, labels_b, lam = mixup_data(\n",
    "                    images, labels, alpha=self.config.training.mixup_alpha\n",
    "                )\n",
    "                outputs = self.model(mixed_images)\n",
    "                cls_loss_a = F.cross_entropy(outputs['logits'], labels_a)\n",
    "                cls_loss_b = F.cross_entropy(outputs['logits'], labels_b)\n",
    "                cls_loss = lam * cls_loss_a + (1 - lam) * cls_loss_b\n",
    "                losses = self.criterion(outputs, (images, masks, labels))\n",
    "                losses['classification'] = cls_loss\n",
    "                losses['total'] = (cls_loss + losses['dice'] + losses['bce'])\n",
    "            elif self.config.training.use_cutmix and use_augmentation and batch_size > 1:\n",
    "                mixed_images, labels_a, labels_b, lam = cutmix_data(\n",
    "                    images, labels, alpha=self.config.training.cutmix_alpha\n",
    "                )\n",
    "                outputs = self.model(mixed_images)\n",
    "                cls_loss_a = F.cross_entropy(outputs['logits'], labels_a)\n",
    "                cls_loss_b = F.cross_entropy(outputs['logits'], labels_b)\n",
    "                cls_loss = lam * cls_loss_a + (1 - lam) * cls_loss_b\n",
    "                losses = self.criterion(outputs, (images, masks, labels))\n",
    "                losses['classification'] = cls_loss\n",
    "                losses['total'] = (cls_loss + losses['dice'] + losses['bce'])\n",
    "            else:\n",
    "                outputs = self.model(images)\n",
    "                losses = self.criterion(outputs, (images, masks, labels))\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            losses['total'].backward()\n",
    "            if self.config.training.gradient_clip > 0:\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), self.config.training.gradient_clip)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += losses['total'].item()\n",
    "            pbar.set_postfix({'loss': f\"{losses['total'].item():.4f}\"})\n",
    "        \n",
    "        if self.scheduler:\n",
    "            self.scheduler.step()\n",
    "        \n",
    "        return total_loss / max(len(self.train_loader), 1)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _calculate_train_accuracy(self) -> float:\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        max_batches = max(1, len(self.train_loader) // 5)\n",
    "        for i, (images, masks, labels, _) in enumerate(self.train_loader):\n",
    "            if i >= max_batches:\n",
    "                break\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            outputs = self.model(images)\n",
    "            _, predicted = outputs['logits'].max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        self.model.train()\n",
    "        return 100.0 * correct / total if total > 0 else 0.0\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self) -> Tuple[float, float, Dict[str, float]]:\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        \n",
    "        for images, masks, labels, original_sizes in self.val_loader:\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            if isinstance(masks, torch.Tensor):\n",
    "                masks = masks.to(self.device)\n",
    "            \n",
    "            outputs = self.model(images)\n",
    "            losses = self.criterion(outputs, (images, masks, labels))\n",
    "            total_loss += losses['total'].item()\n",
    "            \n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            _, predicted = logits.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_probs = np.array(all_probs)\n",
    "        \n",
    "        avg_loss = total_loss / max(len(self.val_loader), 1)\n",
    "        accuracy = 100.0 * accuracy_score(all_labels, all_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='weighted', zero_division=0\n",
    "        )\n",
    "        \n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        y_true_bin = label_binarize(all_labels, classes=range(self.config.model.num_classes))\n",
    "        auc_score = roc_auc_score(y_true_bin, all_probs, average='weighted', multi_class='ovr')\n",
    "        \n",
    "        metrics = {\n",
    "            'precision': precision * 100,\n",
    "            'recall': recall * 100,\n",
    "            'f1': f1 * 100,\n",
    "            'auc': auc_score * 100\n",
    "        }\n",
    "        \n",
    "        return avg_loss, accuracy, metrics\n",
    "    \n",
    "    def save_checkpoint(self, is_best: bool = False, epoch_checkpoint: bool = False):\n",
    "        checkpoint = {\n",
    "            'epoch': self.current_epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\n",
    "            'best_val_acc': self.best_val_acc,\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'history': self.history,\n",
    "            'early_stopping_counter': self.early_stopping_counter,\n",
    "            'config': asdict(self.config)\n",
    "        }\n",
    "        \n",
    "        latest_path = Path(self.config.system.checkpoint_dir) / 'latest.pth'\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        \n",
    "        if is_best:\n",
    "            best_path = Path(self.config.system.checkpoint_dir) / 'best.pth'\n",
    "            torch.save(checkpoint, best_path)\n",
    "            print(f\"    âœ…   âœ“ Saved best checkpoint: {best_path}\")\n",
    "        \n",
    "        if epoch_checkpoint and (self.current_epoch + 1) % self.config.system.save_frequency == 0:\n",
    "            epoch_path = Path(self.config.system.checkpoint_dir) / f'epoch_{self.current_epoch + 1:03d}.pth'\n",
    "            torch.save(checkpoint, epoch_path)\n",
    "            print(f\"    âœ…   âœ“ Saved epoch checkpoint: {epoch_path}\")\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path: str, load_optimizer: bool = True):\n",
    "        if not Path(checkpoint_path).exists():\n",
    "            raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        \n",
    "        print(f\"\\nðŸ¤–     Loading checkpoint from: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(\"âœ…    Model weights loaded\")\n",
    "        \n",
    "        if load_optimizer and 'optimizer_state_dict' in checkpoint:\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            print(\"âœ…    Optimizer state loaded\")\n",
    "        \n",
    "        if load_optimizer and self.scheduler and 'scheduler_state_dict' in checkpoint:\n",
    "            if checkpoint['scheduler_state_dict'] is not None:\n",
    "                self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                print(\"âœ…    Scheduler state loaded\")\n",
    "        \n",
    "        self.current_epoch = checkpoint.get('epoch', 0) + 1\n",
    "        self.best_val_acc = checkpoint.get('best_val_acc', 0.0)\n",
    "        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        self.history = checkpoint.get('history', self.history)\n",
    "        self.early_stopping_counter = checkpoint.get('early_stopping_counter', 0)\n",
    "        \n",
    "        print(f\"âœ…    Training state loaded (epoch {self.current_epoch})\")\n",
    "        print(f\"  Best val accuracy: {self.best_val_acc:.2f}%\")\n",
    "        print(f\"  Best val loss: {self.best_val_loss:.4f}\\n\")\n",
    "    \n",
    "    def train(self):\n",
    "        start_epoch = self.current_epoch\n",
    "        total_epochs = self.config.training.epochs\n",
    "        \n",
    "        print(f\"ðŸ¤–     Starting training...\")\n",
    "        print(f\"   Device: {self.device}\")\n",
    "        print(f\"   Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        print(f\"   Training from epoch {start_epoch + 1} to {total_epochs}\")\n",
    "        \n",
    "        for epoch in range(start_epoch, total_epochs):\n",
    "            self.current_epoch = epoch\n",
    "            train_loss = self.train_epoch()\n",
    "            train_acc = self._calculate_train_accuracy()\n",
    "            val_loss, val_acc, val_metrics = self.validate()\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            self.history['val_precision'].append(val_metrics['precision'])\n",
    "            self.history['val_recall'].append(val_metrics['recall'])\n",
    "            self.history['val_f1'].append(val_metrics['f1'])\n",
    "            self.history['val_auc'].append(val_metrics['auc'])\n",
    "            self.history['learning_rate'].append(self.optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            print(f\"\\nðŸ“Š     Epoch {epoch + 1}/{total_epochs}\")\n",
    "            print(f\"   Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"   Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            print(f\"   Val Precision: {val_metrics['precision']:.2f}%, Recall: {val_metrics['recall']:.2f}%, F1: {val_metrics['f1']:.2f}%\")\n",
    "            print(f\"   Val AUC: {val_metrics['auc']:.2f}%, LR: {self.optimizer.param_groups[0]['lr']:.6f}\")\n",
    "            \n",
    "            is_best = val_acc > self.best_val_acc\n",
    "            if is_best:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.best_val_loss = val_loss\n",
    "                self.early_stopping_counter = 0\n",
    "                print(f\"   âœ…    New best model! Accuracy: {val_acc:.2f}%\")\n",
    "            else:\n",
    "                self.early_stopping_counter += 1\n",
    "            \n",
    "            self.save_checkpoint(is_best=is_best, epoch_checkpoint=True)\n",
    "            \n",
    "            if self.early_stopping_counter >= self.config.training.early_stopping_patience:\n",
    "                print(f\"\\nâœ‹  â¹ï¸    Early stopping triggered after {epoch + 1} epochs\")\n",
    "                print(f\"   No improvement for {self.early_stopping_counter} consecutive epochs\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰     Training complete!\")\n",
    "        print(f\"   Best validation accuracy: {self.best_val_acc:.2f}%\")\n",
    "        print(f\"   Best validation loss: {self.best_val_loss:.4f}\")\n",
    "        self.plot_history()\n",
    "    \n",
    "    def plot_history(self):\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.rcParams['figure.dpi'] = 150\n",
    "        plt.rcParams['savefig.dpi'] = 300\n",
    "        plt.rcParams['font.size'] = 10\n",
    "        \n",
    "        if not self.history['val_acc']:\n",
    "            print(\"âš ï¸    No training history to plot.\")\n",
    "            return\n",
    "        \n",
    "        epochs = range(1, len(self.history['val_acc']) + 1)\n",
    "        print(\"\\nðŸ“Š     Generating comprehensive training visualizations...\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(epochs, self.history['train_acc'], 'o-', linewidth=2.5, markersize=6,\n",
    "                label='Training Accuracy', color='#2E86AB')\n",
    "        plt.plot(epochs, self.history['val_acc'], 's-', linewidth=2.5, markersize=6,\n",
    "                label='Validation Accuracy', color='#A23B72')\n",
    "        plt.xlabel('Epochs', fontsize=13, fontweight='bold')\n",
    "        plt.ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "        plt.title('Training vs Validation Accuracy', fontsize=15, fontweight='bold', pad=15)\n",
    "        plt.legend(loc='lower right', fontsize=11, framealpha=0.95)\n",
    "        plt.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.xlim(left=min(epochs), right=max(epochs))\n",
    "        \n",
    "        best_epoch = int(np.argmax(self.history['val_acc'])) + 1\n",
    "        best_val_acc = max(self.history['val_acc'])\n",
    "        plt.plot(best_epoch, best_val_acc, 'r*', markersize=15, label=f'Best Val Acc: {best_val_acc:.2f}%')\n",
    "        plt.legend(loc='lower right', fontsize=11, framealpha=0.95)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = Path(self.config.system.log_dir) / 'train_val_accuracy_comparison.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   âœ…    Training vs Validation Accuracy curve saved to: {save_path}\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(epochs, self.history['val_acc'], 'o-', linewidth=2, markersize=6,\n",
    "                label='Accuracy (%)', color='#FF6B35')\n",
    "        ax.plot(epochs, self.history['val_precision'], 's-', linewidth=2, markersize=6,\n",
    "                label='Precision (%)', color='#FF9F1C')\n",
    "        ax.plot(epochs, self.history['val_recall'], '^-', linewidth=2, markersize=6,\n",
    "                label='Recall (%)', color='#E71D36')\n",
    "        ax.plot(epochs, self.history['val_f1'], 'd-', linewidth=2, markersize=6,\n",
    "                label='F1-Score (%)', color='#C3073F')\n",
    "        ax.plot(epochs, self.history['val_auc'], 'p-', linewidth=2.5, markersize=6,\n",
    "                label='AUC Score (%)', color='#00A6FB')\n",
    "        ax.set_xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold')\n",
    "        ax.set_title('Performance Metrics Over Epochs', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax.legend(loc='lower right', fontsize=11, framealpha=0.95)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim(left=min(epochs), right=max(epochs))\n",
    "        plt.tight_layout()\n",
    "        save_path = Path(self.config.system.log_dir) / 'performance_metrics_over_epochs.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   âœ…    Performance Metrics Over Epochs saved to: {save_path}\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(epochs, self.history['train_loss'], 'o-', linewidth=2.5, markersize=6,\n",
    "                label='Training Loss', color='#06A77D')\n",
    "        plt.plot(epochs, self.history['val_loss'], 's-', linewidth=2.5, markersize=6,\n",
    "                label='Validation Loss', color='#F77F00')\n",
    "        plt.xlabel('Epochs', fontsize=13, fontweight='bold')\n",
    "        plt.ylabel('Loss', fontsize=13, fontweight='bold')\n",
    "        plt.title('Training and Validation Loss Curves', fontsize=15, fontweight='bold', pad=15)\n",
    "        plt.legend(loc='upper right', fontsize=11, framealpha=0.95)\n",
    "        plt.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.xlim(left=min(epochs), right=max(epochs))\n",
    "        plt.tight_layout()\n",
    "        save_path = Path(self.config.system.log_dir) / 'loss_curves.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   âœ…    Loss curves saved to: {save_path}\")\n",
    "        \n",
    "        print(f\"\\nâœ…    All training visualizations saved to: {self.config.system.log_dir}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATOR CLASS WITH COMPONENT IMPORTANCE VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "class CAMDFNetEvaluator:\n",
    "    def __init__(self, model: CAMDFNet, config: CAMDFNetConfig):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.system.device if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.mask_generator = MaskGenerator()\n",
    "        self.output_dir = Path(config.system.output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        (self.output_dir / 'summary').mkdir(exist_ok=True)\n",
    "        (self.output_dir / 'summary/curves').mkdir(exist_ok=True)\n",
    "        (self.output_dir / 'summary/matrices').mkdir(exist_ok=True)\n",
    "        (self.output_dir / 'per_image_results').mkdir(exist_ok=True)\n",
    "        (self.output_dir / 'component_importance').mkdir(exist_ok=True)\n",
    "        (self.output_dir / 'batch_analysis').mkdir(exist_ok=True)\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "        sns.set_palette(\"husl\")\n",
    "    \n",
    "    def _safe_resize_2d(self, data_2d: np.ndarray, target_wh: Tuple[int, int]) -> np.ndarray:\n",
    "        if data_2d.size == 0:\n",
    "            return np.zeros((target_wh[1], target_wh[0]), dtype=np.float32)\n",
    "        return cv2.resize(data_2d.astype(np.float32), target_wh, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    def _normalize_for_display(self, arr: np.ndarray) -> np.ndarray:\n",
    "        mn, mx = arr.min(), arr.max()\n",
    "        if mx - mn < 1e-8:\n",
    "            return np.zeros_like(arr, dtype=np.float32)\n",
    "        return (arr - mn) / (mx - mn)\n",
    "    \n",
    "    def create_comprehensive_image_folder_structure(self, image_name: str) -> Dict[str, Path]:\n",
    "        base = self.output_dir / 'per_image_results' / image_name\n",
    "        folders = {\n",
    "            'root': base,\n",
    "            '0_original': base / '0_original',\n",
    "            '1_inputs': base / '1_inputs',\n",
    "            '2_preprocessing': base / '2_preprocessing',\n",
    "            '2a_spectral': base / '2_preprocessing/spectral',\n",
    "            '2b_normalized': base / '2_preprocessing/normalized',\n",
    "            '3_cnn_activations': base / '3_cnn_activations',\n",
    "            '3a_cnn_layerwise': base / '3_cnn_activations/layerwise',\n",
    "            '3b_cnn_feature_maps': base / '3_cnn_activations/feature_maps',\n",
    "            '3c_cnn_gradients': base / '3_cnn_activations/gradients',\n",
    "            '3d_cnn_statistics': base / '3_cnn_activations/statistics',\n",
    "            '4_vit_activations': base / '4_vit_activations',\n",
    "            '4a_vit_self_attention': base / '4_vit_activations/self_attention',\n",
    "            '4b_vit_headwise': base / '4_vit_activations/headwise',\n",
    "            '4c_vit_spatial': base / '4_vit_activations/spatial',\n",
    "            '4d_vit_sequence': base / '4_vit_activations/sequence',\n",
    "            '4e_vit_statistics': base / '4_vit_activations/statistics',\n",
    "            '5_fusion_activations': base / '5_fusion_activations',\n",
    "            '5a_cross_attention': base / '5_fusion_activations/cross_attention',\n",
    "            '5b_fused_features': base / '5_fusion_activations/fused_features',\n",
    "            '5c_gated_features': base / '5_fusion_activations/gated',\n",
    "            '6_segmentation_activations': base / '6_segmentation_activations',\n",
    "            '6a_pyramid_pooling': base / '6_segmentation_activations/pyramid_pool',\n",
    "            '6b_attention_refine': base / '6_segmentation_activations/attention_refine',\n",
    "            '6c_mask_generation': base / '6_segmentation_activations/mask_generation',\n",
    "            '6d_segmentation_layers': base / '6_segmentation_activations/layers',\n",
    "            '7_classification_activations': base / '7_classification_activations',\n",
    "            '7a_classifier_features': base / '7_classification_activations/features',\n",
    "            '7b_uncertainty': base / '7_classification_activations/uncertainty',\n",
    "            '7c_probability_dist': base / '7_classification_activations/probabilities',\n",
    "            '8_masks': base / '8_masks',\n",
    "            '8a_predicted_masks': base / '8_masks/predicted',\n",
    "            '8b_ground_truth': base / '8_masks/ground_truth',\n",
    "            '8c_overlays': base / '8_masks/overlays',\n",
    "            '8d_comparisons': base / '8_masks/comparisons',\n",
    "            '9_feature_analysis': base / '9_feature_analysis',\n",
    "            '9a_feature_maps': base / '9_feature_analysis/feature_maps',\n",
    "            '9b_heatmaps': base / '9_feature_analysis/heatmaps',\n",
    "            '9c_pca_analysis': base / '9_feature_analysis/pca',\n",
    "            '9d_tsne_analysis': base / '9_feature_analysis/tsne',\n",
    "            '9e_correlations': base / '9_feature_analysis/correlations',\n",
    "            '10_comprehensive_grids': base / '10_comprehensive_grids',\n",
    "            '10a_activation_grids': base / '10_comprehensive_grids/activations',\n",
    "            '10b_feature_grids': base / '10_comprehensive_grids/features',\n",
    "            '10c_attention_grids': base / '10_comprehensive_grids/attention',\n",
    "            '10d_final_summary': base / '10_comprehensive_grids/summary',\n",
    "            '11_statistics': base / '11_statistics',\n",
    "            '11a_activation_stats': base / '11_statistics/activations',\n",
    "            '11b_gradient_stats': base / '11_statistics/gradients',\n",
    "            '11c_performance_metrics': base / '11_statistics/performance',\n",
    "            '11d_disease_severity': base / '11_statistics/severity',\n",
    "            '12_debug': base / '12_debug',\n",
    "            '12a_intermediate_tensors': base / '12_debug/tensors',\n",
    "            '12b_gradient_flow': base / '12_debug/gradients',\n",
    "            '12c_model_states': base / '12_debug/states',\n",
    "            '13_metadata': base / '13_metadata',\n",
    "            '13a_configurations': base / '13_metadata/configs',\n",
    "            '13b_predictions': base / '13_metadata/predictions',\n",
    "            '13c_analysis_reports': base / '13_metadata/reports',\n",
    "            '13d_visualization_logs': base / '13_metadata/logs',\n",
    "        }\n",
    "        for fn, fp in folders.items():\n",
    "            fp.mkdir(parents=True, exist_ok=True)\n",
    "            if 'layerwise' in fn or ('layers' in fn and 'segmentation' in str(fp)):\n",
    "                for i in range(10):\n",
    "                    (fp / f'layer_{i:03d}').mkdir(exist_ok=True)\n",
    "            if 'headwise' in fn:\n",
    "                for i in range(12):\n",
    "                    (fp / f'head_{i:02d}').mkdir(exist_ok=True)\n",
    "        return folders\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dataloader: DataLoader) -> Dict[str, Any]:\n",
    "        all_preds, all_labels, all_probs, all_uncertainties = [], [], [], []\n",
    "        all_masks_pred, all_masks_true = [], []\n",
    "        all_cross_attentions, all_vit_attentions = [], []\n",
    "        all_spectral_images, all_fused_features = [], []\n",
    "        \n",
    "        for images, masks, labels, original_sizes in tqdm(dataloader, desc='Evaluating'):\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            outputs = self.model(images)\n",
    "            vit_attentions = self.model.get_vit_self_attention(images)\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            _, predicted = logits.max(1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_uncertainties.extend(outputs['uncertainty'].cpu().numpy())\n",
    "            \n",
    "            batch_size = images.size(0)\n",
    "            for i in range(batch_size):\n",
    "                orig_w, orig_h = original_sizes[i]\n",
    "                mask_pred_i = outputs['mask'][i:i+1]\n",
    "                mask_pred_resized = F.interpolate(\n",
    "                    mask_pred_i, size=(int(orig_h), int(orig_w)),\n",
    "                    mode='bilinear', align_corners=True\n",
    "                )\n",
    "                all_masks_pred.append(torch.sigmoid(mask_pred_resized).cpu().numpy()[0])\n",
    "                if isinstance(masks, torch.Tensor):\n",
    "                    mt = masks[i].cpu().numpy()\n",
    "                else:\n",
    "                    mt = masks[i].numpy() if isinstance(masks[i], torch.Tensor) else masks[i]\n",
    "                if mt.ndim == 2:\n",
    "                    mt = mt[np.newaxis, ...]\n",
    "                all_masks_true.append(mt)\n",
    "            \n",
    "            cross_attn = outputs['cross_attention_weights']\n",
    "            if isinstance(cross_attn, tuple):\n",
    "                cross_attn = cross_attn[0]\n",
    "            all_cross_attentions.append(cross_attn.cpu().numpy())\n",
    "            all_vit_attentions.append({k: v.cpu().numpy() for k, v in vit_attentions.items()})\n",
    "            all_spectral_images.extend(outputs['spectral_image'].cpu().numpy())\n",
    "            all_fused_features.extend(outputs['fused_features'].cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_probs = np.array(all_probs)\n",
    "        all_uncertainties = np.array(all_uncertainties)\n",
    "        \n",
    "        if all_cross_attentions:\n",
    "            all_cross_attentions = np.concatenate(all_cross_attentions, axis=0)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        iou_scores, dice_scores = [], []\n",
    "        for mp, mt in zip(all_masks_pred, all_masks_true):\n",
    "            mps, mts = mp.squeeze(), mt.squeeze()\n",
    "            if mps.shape != mts.shape:\n",
    "                mps = cv2.resize(mps, (mts.shape[1], mts.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "            mpb = (mps > 0.5).astype(np.float32).flatten()\n",
    "            mtf = mts.flatten().astype(np.float32)\n",
    "            inter = (mpb * mtf).sum()\n",
    "            union = mpb.sum() + mtf.sum() - inter\n",
    "            iou_scores.append(inter / (union + 1e-8))\n",
    "            dice_scores.append((2 * inter) / (mpb.sum() + mtf.sum() + 1e-8))\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
    "            'f1_score': f1, 'iou': np.mean(iou_scores) if iou_scores else 0.0,\n",
    "            'dice': np.mean(dice_scores) if dice_scores else 0.0,\n",
    "            'predictions': all_preds, 'labels': all_labels,\n",
    "            'probabilities': all_probs, 'uncertainties': all_uncertainties,\n",
    "            'masks_pred': all_masks_pred, 'masks_true': all_masks_true,\n",
    "            'cross_attentions': all_cross_attentions,\n",
    "            'vit_attentions': all_vit_attentions,\n",
    "            'spectral_images': np.array(all_spectral_images),\n",
    "            'fused_features': np.array(all_fused_features)\n",
    "        }\n",
    "    \n",
    "    def visualize_activation_layer(self, activation, layer_name, folder, original_size, cmap='viridis'):\n",
    "        if activation is None: return\n",
    "        anp = activation.squeeze().cpu().float().numpy()\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        \n",
    "        if anp.ndim == 3:\n",
    "            nc = min(anp.shape[0], 16)\n",
    "            cols, rows = 4, (nc + 3) // 4\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*3))\n",
    "            if rows == 1 and cols == 1: axes = np.array([[axes]])\n",
    "            elif rows == 1: axes = axes.reshape(1, -1)\n",
    "            elif cols == 1: axes = axes.reshape(-1, 1)\n",
    "            for idx in range(nc):\n",
    "                r, c = idx // cols, idx % cols\n",
    "                cr = self._safe_resize_2d(anp[idx], tw)\n",
    "                cn = self._normalize_for_display(cr)\n",
    "                im = axes[r, c].imshow(cn, cmap=cmap, aspect='auto')\n",
    "                axes[r, c].set_title(f'Ch {idx}', fontsize=8, fontweight='bold'); axes[r, c].axis('off')\n",
    "                if idx == 0: plt.colorbar(im, ax=axes[r, c], fraction=0.046, pad=0.04)\n",
    "            for idx in range(nc, rows*cols): axes[idx//cols, idx%cols].axis('off')\n",
    "            plt.suptitle(f'{layer_name} - Feature Maps', fontsize=12, fontweight='bold', y=0.98)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folder / f'{layer_name}_feature_grid.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            for idx in range(min(nc, 8)):\n",
    "                cn = self._normalize_for_display(self._safe_resize_2d(anp[idx], tw))\n",
    "                plt.imsave(str(folder / f'{layer_name}_channel_{idx:03d}.png'), cn, cmap=cmap)\n",
    "        elif anp.ndim == 2:\n",
    "            ar = self._safe_resize_2d(anp, tw)\n",
    "            an = self._normalize_for_display(ar)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            im1 = a1.imshow(an, cmap=cmap); a1.set_title(f'{layer_name}', fontsize=10, fontweight='bold'); a1.axis('off')\n",
    "            plt.colorbar(im1, ax=a1, fraction=0.046, pad=0.04)\n",
    "            a2.imshow(an, cmap=cmap, alpha=0.8); a2.contour(an, levels=10, colors='white', alpha=0.5, linewidths=0.5)\n",
    "            a2.set_title(f'{layer_name} - Contours', fontsize=10, fontweight='bold'); a2.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folder / f'{layer_name}_visualization.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            plt.imsave(str(folder / f'{layer_name}_simple.png'), an, cmap=cmap)\n",
    "        elif anp.ndim == 1 and len(anp) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 4))\n",
    "            ax.bar(range(len(anp)), anp, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "            ax.set_title(f'{layer_name}', fontsize=11, fontweight='bold'); ax.grid(True, alpha=0.3, axis='y')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folder / f'{layer_name}_values.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "    \n",
    "    def visualize_activation_statistics(self, activation, layer_name, folder):\n",
    "        if activation is None: return\n",
    "        anp = activation.cpu().float().numpy().flatten()\n",
    "        if len(anp) < 2: return\n",
    "        fig, ((a1,a2),(a3,a4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        a1.hist(anp, bins=min(100, len(anp)), color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        a1.set_title('Distribution', fontsize=11, fontweight='bold'); a1.grid(True, alpha=0.3)\n",
    "        a2.boxplot(anp, vert=True, patch_artist=True, boxprops=dict(facecolor='lightcoral'))\n",
    "        a2.set_title('Box Plot', fontsize=11, fontweight='bold'); a2.grid(True, alpha=0.3, axis='y')\n",
    "        scipy_stats.probplot(anp, dist=\"norm\", plot=a3)\n",
    "        a3.set_title('Q-Q Plot', fontsize=11, fontweight='bold'); a3.grid(True, alpha=0.3)\n",
    "        parts = a4.violinplot(anp, showmeans=True, showmedians=True)\n",
    "        for pc in parts['bodies']:\n",
    "            pc.set_facecolor('lightgreen')\n",
    "            pc.set_alpha(0.7)\n",
    "        a4.set_title('Violin Plot', fontsize=11, fontweight='bold'); a4.grid(True, alpha=0.3, axis='y')\n",
    "        plt.suptitle(f'{layer_name} - Stats', fontsize=13, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / f'{layer_name}_statistics.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        sd = {'layer_name': layer_name, 'mean': float(np.mean(anp)), 'std': float(np.std(anp)),\n",
    "              'min': float(np.min(anp)), 'max': float(np.max(anp)), 'median': float(np.median(anp)),\n",
    "              'skewness': float(scipy_stats.skew(anp)), 'kurtosis': float(scipy_stats.kurtosis(anp)),\n",
    "              'num_elements': len(anp), 'non_zero_pct': float(np.sum(anp!=0)/len(anp)*100)}\n",
    "        with open(str(folder / f'{layer_name}_statistics.json'), 'w') as f:\n",
    "            json.dump(sd, f, indent=2)\n",
    "    \n",
    "    def visualize_gradient_flow(self, gradients, folders, image_name):\n",
    "        if not gradients: return\n",
    "        gm = {n: float(np.sqrt(np.sum(g.cpu().numpy()**2))) for n, g in gradients.items() if g is not None}\n",
    "        if not gm: return\n",
    "        sm = dict(sorted(gm.items(), key=lambda x: x[1], reverse=True))\n",
    "        fig, (a1, a2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        names = list(sm.keys())[:15]; mags = [sm[n] for n in names]\n",
    "        a1.bar(range(len(names)), mags, color='lightcoral', edgecolor='darkred')\n",
    "        a1.set_xticks(range(len(names))); a1.set_xticklabels([n[:20] for n in names], rotation=45, ha='right', fontsize=8)\n",
    "        a1.set_title('Gradient Magnitudes', fontsize=12, fontweight='bold'); a1.grid(True, alpha=0.3, axis='y')\n",
    "        ag = np.concatenate([g.cpu().numpy().flatten() for g in gradients.values() if g is not None])\n",
    "        a2.hist(ag, bins=100, color='lightblue', edgecolor='darkblue', alpha=0.7)\n",
    "        a2.set_title('Gradient Distribution', fontsize=12, fontweight='bold'); a2.grid(True, alpha=0.3)\n",
    "        plt.suptitle(f'Gradient Flow: {image_name}', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folders['3c_cnn_gradients'] / f'{image_name}_gradient_analysis.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    def create_comprehensive_activation_report(self, all_activations, folders, image_name, original_size):\n",
    "        print(f\"    ðŸ“Š Generating comprehensive activation report...\")\n",
    "        cmaps = {'input':'gray','spectral':'viridis','cnn':'plasma','vit':'magma',\n",
    "                 'attention':'hot','fusion':'coolwarm','segmentation':'summer',\n",
    "                 'classification':'spring','mask':'bone'}\n",
    "        \n",
    "        for aname, atensor in all_activations.items():\n",
    "            if atensor is None: continue\n",
    "            nl = aname.lower()\n",
    "            atype, tfolder = 'other', folders['12_debug']\n",
    "            if 'input' in nl: atype, tfolder = 'input', folders['1_inputs']\n",
    "            elif 'spectral' in nl: atype, tfolder = 'spectral', folders['2a_spectral']\n",
    "            elif 'cnn' in nl:\n",
    "                atype = 'cnn'\n",
    "                if 'layer' in aname:\n",
    "                    ln = aname.split('_')[-1]\n",
    "                    ln = ln if ln.isdigit() else '0'\n",
    "                    lf = folders['3a_cnn_layerwise'] / f'layer_{int(ln):03d}'\n",
    "                    lf.mkdir(exist_ok=True); tfolder = lf\n",
    "                else: tfolder = folders['3b_cnn_feature_maps']\n",
    "            elif 'vit' in nl:\n",
    "                atype = 'vit'\n",
    "                if 'spatial' in nl: tfolder = folders['4c_vit_spatial']\n",
    "                elif 'sequence' in nl: tfolder = folders['4d_vit_sequence']\n",
    "                else: tfolder = folders['4_vit_activations']\n",
    "            elif 'attention' in nl:\n",
    "                atype = 'attention'\n",
    "                if 'cross' in nl: tfolder = folders['5a_cross_attention']\n",
    "                elif 'self' in nl: tfolder = folders['4a_vit_self_attention']\n",
    "                else: tfolder = folders['6b_attention_refine']\n",
    "            elif 'fusion' in nl or 'fused' in nl: atype, tfolder = 'fusion', folders['5_fusion_activations']\n",
    "            elif 'mask' in nl or 'seg' in nl: atype, tfolder = 'segmentation', folders['6_segmentation_activations']\n",
    "            elif 'class' in nl or 'logit' in nl: atype, tfolder = 'classification', folders['7_classification_activations']\n",
    "            elif 'uncertainty' in nl: atype, tfolder = 'classification', folders['7b_uncertainty']\n",
    "            elif 'pool' in nl: atype, tfolder = 'segmentation', folders['6a_pyramid_pooling']\n",
    "            elif 'proj' in nl: atype, tfolder = 'cnn', folders['3_cnn_activations']\n",
    "            elif 'gated' in nl: atype, tfolder = 'fusion', folders['5c_gated_features']\n",
    "            tfolder.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            print(f\"      ðŸ“ˆ Visualizing {aname}...\")\n",
    "            self.visualize_activation_layer(atensor, aname, tfolder, original_size, cmaps.get(atype, 'viridis'))\n",
    "            if atensor.numel() < 1000000:\n",
    "                sf = folders['11a_activation_stats']; sf.mkdir(exist_ok=True)\n",
    "                self.visualize_activation_statistics(atensor, aname, sf)\n",
    "                if atensor.numel() < 10000:\n",
    "                    np.save(str(folders['12a_intermediate_tensors'] / f'{aname}.npy'), atensor.cpu().numpy())\n",
    "                else:\n",
    "                    s = {'name': aname, 'shape': list(atensor.shape),\n",
    "                         'mean': float(atensor.float().mean()), 'std': float(atensor.float().std()),\n",
    "                         'min': float(atensor.float().min()), 'max': float(atensor.float().max()),\n",
    "                         'numel': int(atensor.numel())}\n",
    "                    with open(str(folders['12a_intermediate_tensors'] / f'{aname}_summary.json'), 'w') as f:\n",
    "                        json.dump(s, f, indent=2)\n",
    "        \n",
    "        self.create_activation_summary_grid(all_activations, folders, image_name, original_size)\n",
    "        self._create_feature_analysis(all_activations, folders, image_name, original_size)\n",
    "        self._create_prob_uncertainty_viz(all_activations, folders, image_name)\n",
    "        self._create_comparison_viz(all_activations, folders, image_name, original_size)\n",
    "    \n",
    "    def _create_feature_analysis(self, all_activations, folders, image_name, original_size):\n",
    "        print(f\"      ðŸ“Š Creating feature analysis...\")\n",
    "        kf = {}\n",
    "        for n, t in all_activations.items():\n",
    "            if any(kw in n.lower() for kw in ['feature','fused','cnn_aligned','vit_spatial']):\n",
    "                if t is not None and 1 < t.numel() < 100000:\n",
    "                    flat = t.cpu().float().numpy().flatten()[:5000]\n",
    "                    if len(flat) > 1: kf[n] = flat\n",
    "        if not kf: return\n",
    "        \n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        for name, tensor in all_activations.items():\n",
    "            if tensor is None or tensor.dim() != 4: continue\n",
    "            if tensor.size(1) >= 3:\n",
    "                fm = np.transpose(tensor[0,:3].cpu().float().numpy(), (1,2,0))\n",
    "            else:\n",
    "                f2d = tensor[0].mean(dim=0).cpu().float().numpy()\n",
    "                fm = np.stack([f2d]*3, axis=-1)\n",
    "            fr = cv2.resize(fm, tw, interpolation=cv2.INTER_CUBIC)\n",
    "            plt.imsave(str(folders['9a_feature_maps'] / f'{name}_feature_map.png'), self._normalize_for_display(fr))\n",
    "        for name, tensor in all_activations.items():\n",
    "            if tensor is None or tensor.dim() < 2: continue\n",
    "            if tensor.dim() == 4: hd = tensor[0].mean(dim=0).cpu().float().numpy()\n",
    "            elif tensor.dim() == 3: hd = tensor[0].mean(dim=0).cpu().float().numpy() if tensor.size(0)>1 else tensor.mean(dim=0).cpu().float().numpy()\n",
    "            elif tensor.dim() == 2: hd = tensor.cpu().float().numpy()\n",
    "            else: continue\n",
    "            if hd.ndim != 2 or hd.size < 4: continue\n",
    "            hr = self._safe_resize_2d(hd, tw)\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            im = ax.imshow(hr, cmap='hot', aspect='auto'); ax.set_title(f'{name}', fontsize=12, fontweight='bold'); ax.axis('off')\n",
    "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "            plt.savefig(str(folders['9b_heatmaps'] / f'{name}_heatmap.png'), dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "        \n",
    "        if len(kf) >= 2:\n",
    "            from sklearn.decomposition import PCA\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            fns = list(kf.keys()); fvs = [kf[n] for n in fns]\n",
    "            ml = max(len(v) for v in fvs)\n",
    "            fm = np.zeros((len(fvs), ml))\n",
    "            for i, v in enumerate(fvs): fm[i,:len(v)] = v[:ml]\n",
    "            nc = min(3, len(fns), fm.shape[1])\n",
    "            if nc >= 2:\n",
    "                fs = StandardScaler().fit_transform(fm)\n",
    "                pca = PCA(n_components=nc); pc = pca.fit_transform(fs); ev = pca.explained_variance_ratio_\n",
    "                fig, ax = plt.subplots(figsize=(10, 8))\n",
    "                sc = ax.scatter(pc[:,0], pc[:,1], c=range(len(fns)), cmap='viridis', s=100, alpha=0.7)\n",
    "                for i, n in enumerate(fns): ax.annotate(n[:15], (pc[i,0], pc[i,1]), fontsize=8)\n",
    "                ax.set_title(f'PCA: PC1:{ev[0]:.2%}, PC2:{ev[1]:.2%}', fontsize=12, fontweight='bold')\n",
    "                plt.colorbar(sc, ax=ax); plt.tight_layout()\n",
    "                plt.savefig(str(folders['9c_pca_analysis'] / f'{image_name}_pca.png'), dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "        \n",
    "        if len(kf) >= 3:\n",
    "            from sklearn.manifold import TSNE\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            fns = list(kf.keys()); fvs = [kf[n] for n in fns]\n",
    "            ml = max(len(v) for v in fvs)\n",
    "            fm = np.zeros((len(fvs), ml))\n",
    "            for i, v in enumerate(fvs): fm[i,:len(v)] = v[:ml]\n",
    "            perp = min(5, len(fns)-1)\n",
    "            if perp >= 1:\n",
    "                fs = StandardScaler().fit_transform(fm)\n",
    "                tr = TSNE(n_components=2, random_state=42, perplexity=perp, n_iter=300).fit_transform(fs)\n",
    "                fig, ax = plt.subplots(figsize=(10, 8))\n",
    "                sc = ax.scatter(tr[:,0], tr[:,1], c=range(len(fns)), cmap='plasma', s=100, alpha=0.7)\n",
    "                for i, n in enumerate(fns): ax.annotate(n[:15], (tr[i,0], tr[i,1]), fontsize=8)\n",
    "                ax.set_title(f't-SNE: {image_name}', fontsize=12, fontweight='bold')\n",
    "                plt.colorbar(sc, ax=ax); plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "                plt.savefig(str(folders['9d_tsne_analysis'] / f'{image_name}_tsne.png'), dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "        \n",
    "        if len(kf) >= 2:\n",
    "            from scipy.stats import pearsonr\n",
    "            fns = list(kf.keys()); fvs = [kf[n] for n in fns]\n",
    "            ml = max(len(v) for v in fvs)\n",
    "            fm = np.zeros((len(fvs), ml))\n",
    "            for i, v in enumerate(fvs): fm[i,:len(v)] = v[:ml]\n",
    "            nf = len(fns); cm = np.zeros((nf, nf))\n",
    "            for i in range(nf):\n",
    "                for j in range(nf): cm[i,j], _ = pearsonr(fm[i], fm[j])\n",
    "            fig, ax = plt.subplots(figsize=(12, 10))\n",
    "            im = ax.imshow(cm, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "            ax.set_xticks(range(nf)); ax.set_yticks(range(nf))\n",
    "            ax.set_xticklabels([n[:15] for n in fns], rotation=45, ha='right', fontsize=8)\n",
    "            ax.set_yticklabels([n[:15] for n in fns], fontsize=8)\n",
    "            ax.set_title(f'Correlation: {image_name}', fontsize=14, fontweight='bold')\n",
    "            plt.colorbar(im, ax=ax); plt.tight_layout()\n",
    "            plt.savefig(str(folders['9e_correlations'] / f'{image_name}_correlation.png'), dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "    \n",
    "    def _create_prob_uncertainty_viz(self, all_activations, folders, image_name):\n",
    "        print(f\"      ðŸ“ˆ Creating probability/uncertainty visualizations...\")\n",
    "        if 'cls_logits' in all_activations and all_activations['cls_logits'] is not None:\n",
    "            probs = F.softmax(all_activations['cls_logits'], dim=1).cpu().numpy()[0]\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            bars = ax.bar(range(len(probs)), probs, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "            ax.set_xlabel('Class'); ax.set_ylabel('Probability'); ax.set_ylim([0, 1.1])\n",
    "            ax.set_title(f'Probabilities: {image_name}', fontsize=12, fontweight='bold'); ax.grid(True, alpha=0.3, axis='y')\n",
    "            for b, p in zip(bars, probs): ax.text(b.get_x()+b.get_width()/2., b.get_height()+0.01, f'{p:.3f}', ha='center', fontsize=9)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folders['7c_probability_dist'] / f'{image_name}_probs.png'), dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "        if 'uncertainty' in all_activations and all_activations['uncertainty'] is not None:\n",
    "            uv = all_activations['uncertainty'].cpu().numpy().flatten()[0]\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            ax.bar(['Uncertainty'], [uv], color='lightblue', alpha=0.7)\n",
    "            ax.set_ylim([0, 1]); ax.set_title(f'Uncertainty: {uv:.3f}', fontsize=11, fontweight='bold'); ax.grid(True, alpha=0.3, axis='y')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folders['7b_uncertainty'] / f'{image_name}_uncertainty.png'), dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "    \n",
    "    def _create_comparison_viz(self, all_activations, folders, image_name, original_size):\n",
    "        print(f\"      ðŸ”„ Creating comparison visualizations...\")\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        attn_names = [n for n in all_activations.keys() if 'attention' in n.lower()]\n",
    "        if len(attn_names) >= 2:\n",
    "            fig, axes = plt.subplots(1, min(3, len(attn_names)), figsize=(15, 5))\n",
    "            if not isinstance(axes, np.ndarray): axes = [axes]\n",
    "            for idx, an in enumerate(attn_names[:len(axes)]):\n",
    "                t = all_activations[an]\n",
    "                if t is not None:\n",
    "                    am = t.squeeze().cpu().float().numpy()\n",
    "                    if am.ndim == 2:\n",
    "                        ar = self._safe_resize_2d(am, tw)\n",
    "                        axes[idx].imshow(ar, cmap='hot'); axes[idx].set_title(an[:20], fontsize=10, fontweight='bold'); axes[idx].axis('off')\n",
    "            plt.suptitle(f'Attention Comparison: {image_name}', fontsize=12, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folders['8d_comparisons'] / f'{image_name}_attn_comparison.png'), dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "    \n",
    "    def create_activation_summary_grid(self, all_activations, folders, image_name, original_size):\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        key_acts = {\n",
    "            'Input': all_activations.get('input'), 'Spectral': all_activations.get('spectral_output'),\n",
    "            'CNN Features': all_activations.get('cnn_features_raw'), 'ViT Spatial': all_activations.get('vit_spatial'),\n",
    "            'Fused': all_activations.get('fused_features'), 'Cross Attn': all_activations.get('cross_attention_output'),\n",
    "            'Attn Refine': all_activations.get('attention_output'), 'Mask Logits': all_activations.get('mask_logits'),\n",
    "            'Final Mask': all_activations.get('final_mask'), 'Cls Logits': all_activations.get('cls_logits')\n",
    "        }\n",
    "        key_acts = {k: v for k, v in key_acts.items() if v is not None}\n",
    "        if not key_acts: return\n",
    "        cols = 4; rows = (len(key_acts) + cols - 1) // cols\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*3.5))\n",
    "        if rows == 1 and cols == 1: axes = np.array([[axes]])\n",
    "        elif rows == 1: axes = axes.reshape(1, -1)\n",
    "        elif cols == 1: axes = axes.reshape(-1, 1)\n",
    "        \n",
    "        for idx, (name, act) in enumerate(key_acts.items()):\n",
    "            r, c = idx // cols, idx % cols\n",
    "            anp = act.squeeze().cpu().float().numpy()\n",
    "            if anp.ndim == 3: anp = anp.mean(axis=0)\n",
    "            elif anp.ndim == 4: anp = anp.mean(axis=(0, 1))\n",
    "            elif anp.ndim > 4: anp = anp.mean(axis=tuple(range(anp.ndim - 2)))\n",
    "            elif anp.ndim < 2:\n",
    "                axes[r, c].text(0.5, 0.5, f'{name}\\n{anp}', ha='center', va='center', fontsize=10)\n",
    "                axes[r, c].set_title(name, fontsize=9, fontweight='bold'); axes[r, c].axis('off'); continue\n",
    "            \n",
    "            ar = self._safe_resize_2d(anp, tw)\n",
    "            an = self._normalize_for_display(ar)\n",
    "            cmap = 'gray' if 'mask' in name.lower() else ('hot' if 'attn' in name.lower() else 'viridis')\n",
    "            axes[r, c].imshow(an, cmap=cmap)\n",
    "            axes[r, c].set_title(name, fontsize=9, fontweight='bold', pad=3); axes[r, c].axis('off')\n",
    "        \n",
    "        for idx in range(len(key_acts), rows*cols): axes[idx//cols, idx%cols].axis('off')\n",
    "        plt.suptitle(f'Activation Summary: {image_name}', fontsize=14, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folders['10a_activation_grids'] / f'{image_name}_activation_summary.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    def compute_disease_severity(self, mask: np.ndarray) -> Dict[str, Any]:\n",
    "        mb = (mask > 127).astype(np.uint8)\n",
    "        total = mb.size; affected = int(np.sum(mb)); pct = (affected / total) * 100\n",
    "        nl, li = cv2.connectedComponents(mb)\n",
    "        num_lesions = nl - 1\n",
    "        if num_lesions > 0:\n",
    "            ls = [int(np.sum(li == i)) for i in range(1, nl)]\n",
    "            avg_ls, max_ls = float(np.mean(ls)), float(np.max(ls))\n",
    "        else:\n",
    "            avg_ls, max_ls = 0.0, 0.0\n",
    "        if pct < 2: sl = \"Healthy\"\n",
    "        elif pct < 5: sl = \"Minimal\"\n",
    "        elif pct < 15: sl = \"Mild\"\n",
    "        elif pct < 30: sl = \"Moderate\"\n",
    "        elif pct < 50: sl = \"Severe\"\n",
    "        else: sl = \"Critical\"\n",
    "        return {'affected_percentage': pct, 'severity_level': sl, 'num_lesions': num_lesions,\n",
    "                'avg_lesion_size': avg_ls, 'max_lesion_size': max_ls,\n",
    "                'total_affected_pixels': affected, 'total_pixels': total}\n",
    "    \n",
    "    def generate_recommendation(self, severity, confidence):\n",
    "        sl = severity['severity_level']\n",
    "        if sl == \"Critical\" and confidence > 0.8: return \"ðŸš¨ URGENT: Immediate treatment required.\"\n",
    "        elif sl == \"Severe\": return \"âš ï¸ Apply fungicide immediately.\"\n",
    "        elif sl == \"Moderate\": return \"ðŸ“‹ Treat within 48 hours.\"\n",
    "        elif sl == \"Mild\": return \"ðŸ‘€ Monitor. Consider preventive treatment.\"\n",
    "        elif sl == \"Minimal\": return \"âœ… Minor issue. Monitor.\"\n",
    "        else: return \"ðŸŒ¿ HEALTHY: No action needed.\"\n",
    "    \n",
    "    def create_ultimate_comprehensive_grid(self, image_name, original_img, pred_mask, gt_mask,\n",
    "                                          all_activations, pred_class, class_name, confidence,\n",
    "                                          severity, folders, original_size):\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        fig = plt.figure(figsize=(28, 20))\n",
    "        gs = gridspec.GridSpec(6, 6, hspace=0.4, wspace=0.4)\n",
    "        \n",
    "        ax1 = fig.add_subplot(gs[0, 0]); ax1.imshow(original_img)\n",
    "        ax1.set_title(f'Original {tw[0]}x{tw[1]}', fontsize=10, fontweight='bold'); ax1.axis('off')\n",
    "        \n",
    "        ax2 = fig.add_subplot(gs[0, 1]); ax2.imshow(pred_mask, cmap='gray')\n",
    "        ax2.set_title(f'Pred Mask\\n{severity[\"affected_percentage\"]:.1f}%', fontsize=10, fontweight='bold'); ax2.axis('off')\n",
    "        \n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        if gt_mask is not None:\n",
    "            gmu = (gt_mask * 255).astype(np.uint8) if gt_mask.max() <= 1 else gt_mask.astype(np.uint8)\n",
    "            ax3.imshow(gmu, cmap='gray'); ax3.set_title('GT Mask', fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'No GT', ha='center', va='center', fontsize=12)\n",
    "            ax3.set_title('GT Mask', fontsize=10, fontweight='bold')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        ax4 = fig.add_subplot(gs[0, 3])\n",
    "        mc = cv2.applyColorMap(pred_mask, cv2.COLORMAP_JET)\n",
    "        ov = cv2.addWeighted(original_img, 0.6, mc, 0.4, 0)\n",
    "        ax4.imshow(ov); ax4.set_title('Pred Overlay', fontsize=10, fontweight='bold'); ax4.axis('off')\n",
    "        \n",
    "        ax5 = fig.add_subplot(gs[0, 4])\n",
    "        if gt_mask is not None:\n",
    "            gmu = (gt_mask * 255).astype(np.uint8) if gt_mask.max() <= 1 else gt_mask.astype(np.uint8)\n",
    "            gc = cv2.applyColorMap(gmu, cv2.COLORMAP_JET)\n",
    "            if original_img.shape[:2] != gc.shape[:2]:\n",
    "                gc = cv2.resize(gc, (original_img.shape[1], original_img.shape[0]))\n",
    "            ax5.imshow(cv2.addWeighted(original_img, 0.6, gc, 0.4, 0))\n",
    "            ax5.set_title('GT Overlay', fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            ax5.text(0.5, 0.5, 'No GT', ha='center', va='center')\n",
    "            ax5.set_title('GT Overlay', fontsize=10, fontweight='bold')\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        ax6 = fig.add_subplot(gs[0, 5])\n",
    "        st = f\"âš•ï¸ SEVERITY\\n\\nLevel: {severity['severity_level']}\\nAffected: {severity['affected_percentage']:.1f}%\\nLesions: {severity['num_lesions']}\"\n",
    "        ax6.text(0.1, 0.5, st, fontsize=11, va='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        ax6.set_title('Severity', fontsize=10, fontweight='bold'); ax6.axis('off')\n",
    "        \n",
    "        for row_idx, (prefix, cmap, label) in enumerate(\n",
    "            [('cnn', 'plasma', 'CNN'), ('vit', 'magma', 'ViT'), ('attention', 'hot', 'Attn/Fusion')], start=1):\n",
    "            keys = [k for k in all_activations.keys() if prefix in k.lower()]\n",
    "            if prefix == 'attention':\n",
    "                keys += [k for k in all_activations.keys() if 'fused' in k.lower()]\n",
    "            for idx, aname in enumerate(keys[:3]):\n",
    "                ax = fig.add_subplot(gs[row_idx, idx*2:(idx*2)+2])\n",
    "                act = all_activations[aname]\n",
    "                if act is not None:\n",
    "                    anp = act.squeeze().cpu().float().numpy()\n",
    "                    if anp.ndim == 3: anp = anp.mean(axis=0)\n",
    "                    elif anp.ndim < 2: ax.text(0.5, 0.5, f'{aname[:20]}', ha='center', va='center'); ax.axis('off'); continue\n",
    "                    ar = self._safe_resize_2d(anp, tw)\n",
    "                    ax.imshow(self._normalize_for_display(ar), cmap=cmap)\n",
    "                    ax.set_title(f'{label}: {aname[:20]}', fontsize=9, fontweight='bold'); ax.axis('off')\n",
    "        \n",
    "        seg_keys = [k for k in all_activations.keys() if any(w in k.lower() for w in ['mask','seg','pool'])]\n",
    "        for idx, aname in enumerate(seg_keys[:3]):\n",
    "            ax = fig.add_subplot(gs[4, idx*2:(idx*2)+2])\n",
    "            act = all_activations[aname]\n",
    "            if act is not None:\n",
    "                anp = act.squeeze().cpu().float().numpy()\n",
    "                if anp.ndim == 3: anp = anp.mean(axis=0)\n",
    "                elif anp.ndim < 2: ax.text(0.5, 0.5, f'{aname[:20]}', ha='center', va='center'); ax.axis('off'); continue\n",
    "                ax.imshow(self._normalize_for_display(self._safe_resize_2d(anp, tw)), cmap='summer')\n",
    "                ax.set_title(f'Seg: {aname[:20]}', fontsize=9, fontweight='bold'); ax.axis('off')\n",
    "        \n",
    "        ax_s = fig.add_subplot(gs[5, :])\n",
    "        summary = (f\"ðŸŽ¯ CAMDF-NET  REPORT\\nImage: {image_name} | Size: {tw[0]}x{tw[1]}\\n\"\n",
    "                   f\"Predicted: {class_name} ({confidence:.2%}) | Severity: {severity['severity_level']} ({severity['affected_percentage']:.1f}%)\\n\"\n",
    "                   f\"Lesions: {severity['num_lesions']} | Activations: {len(all_activations)}\\n\"\n",
    "                   f\"Recommendation: {self.generate_recommendation(severity, confidence)}\")\n",
    "        ax_s.text(0.1, 0.5, summary, fontsize=12, va='center', bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "        ax_s.set_title('DIAGNOSIS SUMMARY', fontsize=14, fontweight='bold'); ax_s.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'CAMDF-Net  - COMPREHENSIVE: {image_name}', fontsize=16, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout()\n",
    "        sp = str(folders['10d_final_summary'] / f'{image_name}_ULTIMATE_grid.png')\n",
    "        plt.savefig(sp, dpi=300, bbox_inches='tight', facecolor='white'); plt.close()\n",
    "        return sp\n",
    "    \n",
    "    def count_visualizations(self, folder_path):\n",
    "        return sum(1 for _ in folder_path.rglob('*.png')) + sum(1 for _ in folder_path.rglob('*.jpg'))\n",
    "    \n",
    "    def generate_visualization_summary(self, folders, image_name, saved_paths):\n",
    "        summary = {'image_name': image_name, 'timestamp': datetime.datetime.now().isoformat(),\n",
    "                   'total_visualizations': self.count_visualizations(folders['root']),\n",
    "                   'folders': {}, 'key_files': saved_paths}\n",
    "        for fn, fp in folders.items():\n",
    "            if fp.exists():\n",
    "                total = sum(len(list(fp.rglob(f'*.{ext}'))) for ext in ['png','jpg','npy','json','txt'])\n",
    "                if total > 0:\n",
    "                    summary['folders'][fn] = {'total': total}\n",
    "        with open(str(folders['13_metadata'] / f'{image_name}_summary.json'), 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        html = f\"\"\"<!DOCTYPE html><html><head><title>CAMDF-Net Report: {image_name}</title>\n",
    "        <style>body{{font-family:Arial;margin:40px;background:#f5f5f5}}.header{{background:#2c3e50;color:white;padding:20px;border-radius:10px}}\n",
    "        .section{{background:white;padding:20px;margin:20px 0;border-radius:10px;box-shadow:0 2px 5px rgba(0,0,0,0.1)}}</style></head>\n",
    "        <body><div class=\"header\"><h1>CAMDF-Net  Report: {image_name}</h1>\n",
    "        <p>Generated: {datetime.datetime.now().strftime('%Y-%m-d %H:%M:%S')}</p></div>\n",
    "        <div class=\"section\"><h3>Summary</h3><p>Total Visualizations: {summary['total_visualizations']}</p>\n",
    "        <p>Folders: {len(summary['folders'])}</p></div></body></html>\"\"\"\n",
    "        with open(str(folders['13_metadata'] / f'{image_name}_report.html'), 'w') as f:\n",
    "            f.write(html)\n",
    "        print(f\"    ðŸ“‹ Summary saved\")\n",
    "    \n",
    "    def visualize_component_importance(self, image_path, class_names, ground_truth_label=None):\n",
    "        print(f\"\\nðŸ”¬ Visualizing Component Importance for: {Path(image_path).name}\")\n",
    "        \n",
    "        original_image = Image.open(image_path).convert('RGB')\n",
    "        original_size = original_image.size\n",
    "        original_img_np = np.array(original_image)\n",
    "        image_name = Path(image_path).stem\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((self.config.dataset.image_size, self.config.dataset.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image_tensor = transform(original_image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "            all_activations = self.model.get_all_activations()\n",
    "        \n",
    "        probs = F.softmax(outputs['logits'], dim=1).cpu().numpy()[0]\n",
    "        pred_class = int(np.argmax(probs))\n",
    "        confidence = float(probs[pred_class])\n",
    "        pred_class_name = class_names[pred_class]\n",
    "        \n",
    "        if ground_truth_label is not None:\n",
    "            gt_class_name = class_names[ground_truth_label]\n",
    "            gt_correct = (ground_truth_label == pred_class)\n",
    "        else:\n",
    "            gt_class_name = \"Unknown\"\n",
    "            gt_correct = None\n",
    "        \n",
    "        spectral_image = outputs['spectral_image'].cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        vit_attention = all_activations.get('vit_spatial', None)\n",
    "        cnn_features = all_activations.get('cnn_features_raw', None)\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = gridspec.GridSpec(3, 4, hspace=0.3, wspace=0.3, width_ratios=[1, 1, 1, 0.8])\n",
    "        \n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        ax1.imshow(original_img_np)\n",
    "        ax1.set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "        ax1.text(0.02, 0.98, f'Size: {original_size[0]}Ã—{original_size[1]}', \n",
    "                 transform=ax1.transAxes, fontsize=9, color='white',\n",
    "                 bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        if spectral_image is not None:\n",
    "            spectral_display = cv2.resize(spectral_image, (256, 256))\n",
    "            spectral_display = self._normalize_for_display(spectral_display)\n",
    "            original_resized = cv2.resize(original_img_np, (256, 256)) / 255.0\n",
    "            spectral_importance = float(np.abs(spectral_display - original_resized).mean())\n",
    "            ax2.imshow(spectral_display)\n",
    "            ax2.set_title(f'Spectral Component\\nImportance: {spectral_importance:.3f}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "            ax2.text(0.02, 0.98, f'Frequency Features', \n",
    "                    transform=ax2.transAxes, fontsize=9, color='white',\n",
    "                    bbox=dict(boxstyle='round', facecolor='blue', alpha=0.7))\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Spectral\\nNot Available', \n",
    "                    ha='center', va='center', fontsize=12)\n",
    "            ax2.set_title('Spectral Component', fontsize=12, fontweight='bold')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        if vit_attention is not None:\n",
    "            vit_attn = vit_attention.squeeze().cpu().numpy()\n",
    "            if vit_attn.ndim == 3:\n",
    "                vit_attn_2d = vit_attn.mean(axis=0)\n",
    "                vit_attn_display = cv2.resize(vit_attn_2d, (256, 256))\n",
    "                vit_attn_display = self._normalize_for_display(vit_attn_display)\n",
    "                \n",
    "                im3 = ax3.imshow(vit_attn_display, cmap='hot', alpha=0.8)\n",
    "                ax3.imshow(cv2.resize(original_img_np, (256, 256)), alpha=0.4)\n",
    "                \n",
    "                vit_importance = float(vit_attn_display.mean())\n",
    "                ax3.set_title(f'ViT Attention\\nImportance: {vit_importance:.3f}', \n",
    "                             fontsize=12, fontweight='bold')\n",
    "                ax3.text(0.02, 0.98, f'Global Context Attention', \n",
    "                        transform=ax3.transAxes, fontsize=9, color='white',\n",
    "                        bbox=dict(boxstyle='round', facecolor='red', alpha=0.7))\n",
    "                \n",
    "                plt.colorbar(im3, ax=ax3, fraction=0.046, pad=0.04)\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'ViT Attention\\nNot Available', \n",
    "                    ha='center', va='center', fontsize=12)\n",
    "            ax3.set_title('ViT Attention', fontsize=12, fontweight='bold')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        ax4 = fig.add_subplot(gs[0, 3])\n",
    "        if cnn_features is not None:\n",
    "            cnn_feat = cnn_features.squeeze().cpu().numpy()\n",
    "            if cnn_feat.ndim == 3:\n",
    "                cnn_feat_2d = cnn_feat.mean(axis=0)\n",
    "                cnn_feat_display = cv2.resize(cnn_feat_2d, (256, 256))\n",
    "                cnn_feat_display = self._normalize_for_display(cnn_feat_display)\n",
    "                \n",
    "                im4 = ax4.imshow(cnn_feat_display, cmap='viridis', alpha=0.8)\n",
    "                ax4.imshow(cv2.resize(original_img_np, (256, 256)), alpha=0.4)\n",
    "                \n",
    "                cnn_importance = float(cnn_feat_display.mean())\n",
    "                ax4.set_title(f'EfficientNet Features\\nImportance: {cnn_importance:.3f}', \n",
    "                             fontsize=12, fontweight='bold')\n",
    "                ax4.text(0.02, 0.98, f'Local Texture Features', \n",
    "                        transform=ax4.transAxes, fontsize=9, color='white',\n",
    "                        bbox=dict(boxstyle='round', facecolor='green', alpha=0.7))\n",
    "                \n",
    "                plt.colorbar(im4, ax=ax4, fraction=0.046, pad=0.04)\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'EfficientNet\\nNot Available', \n",
    "                    ha='center', va='center', fontsize=12)\n",
    "            ax4.set_title('EfficientNet Features', fontsize=12, fontweight='bold')\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        ax5 = fig.add_subplot(gs[1, 0])\n",
    "        if 'final_mask' in all_activations:\n",
    "            pred_mask = all_activations['final_mask'].squeeze().cpu().numpy()\n",
    "            if pred_mask.ndim == 2:\n",
    "                pred_mask_display = cv2.resize(pred_mask, (256, 256))\n",
    "                ax5.imshow(pred_mask_display, cmap='gray')\n",
    "                mask_coverage = float((pred_mask_display > 0.5).mean())\n",
    "                ax5.set_title(f'Predicted Disease Mask\\nCoverage: {mask_coverage:.2%}', \n",
    "                             fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            ax5.text(0.5, 0.5, 'Predicted Mask\\nNot Available', \n",
    "                    ha='center', va='center', fontsize=12)\n",
    "            ax5.set_title('Predicted Disease Mask', fontsize=12, fontweight='bold')\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        ax6 = fig.add_subplot(gs[1, 1:])\n",
    "        components = ['Spectral', 'ViT Attention', 'EfficientNet']\n",
    "        importances = [\n",
    "            spectral_importance if 'spectral_importance' in locals() else 0,\n",
    "            vit_importance if 'vit_importance' in locals() else 0,\n",
    "            cnn_importance if 'cnn_importance' in locals() else 0\n",
    "        ]\n",
    "        \n",
    "        colors = ['blue', 'red', 'green']\n",
    "        bars = ax6.bar(components, importances, color=colors, edgecolor='black', alpha=0.7)\n",
    "        \n",
    "        for bar, imp in zip(bars, importances):\n",
    "            height = bar.get_height()\n",
    "            ax6.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{imp:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        ax6.set_ylabel('Importance Score', fontsize=11, fontweight='bold')\n",
    "        ax6.set_title('Component Importance Comparison', fontsize=13, fontweight='bold')\n",
    "        ax6.grid(True, alpha=0.3, axis='y')\n",
    "        ax6.set_ylim([0, max(importances) * 1.2 if importances else 1])\n",
    "        \n",
    "        ax7 = fig.add_subplot(gs[2, 0])\n",
    "        if sum(importances) > 0:\n",
    "            normalized_imp = [imp/sum(importances) for imp in importances]\n",
    "            wedges, texts, autotexts = ax7.pie(normalized_imp, labels=components, colors=colors,\n",
    "                                              autopct='%1.1f%%', startangle=90,\n",
    "                                              textprops={'fontsize': 10, 'fontweight': 'bold'})\n",
    "            for autotext in autotexts:\n",
    "                autotext.set_color('white')\n",
    "                autotext.set_fontweight('bold')\n",
    "            ax7.set_title('Relative Importance (%)', fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            ax7.text(0.5, 0.5, 'No importance data\\navailable', \n",
    "                    ha='center', va='center', fontsize=12)\n",
    "            ax7.set_title('Relative Importance', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        ax8 = fig.add_subplot(gs[2, 1:])\n",
    "        ax8.axis('off')\n",
    "        \n",
    "        info_text = \"=\" * 60 + \"\\n\"\n",
    "        info_text += \"PREDICTION RESULTS\\n\"\n",
    "        info_text += \"=\" * 60 + \"\\n\\n\"\n",
    "        info_text += f\"ðŸŒ¿ Image: {image_name}\\n\"\n",
    "        info_text += f\"ðŸ“ Original Size: {original_size[0]} Ã— {original_size[1]}\\n\"\n",
    "        info_text += f\"ðŸŽ¯ Predicted Class: {pred_class_name} (Class {pred_class})\\n\"\n",
    "        info_text += f\"ðŸ“ˆ Confidence: {confidence:.2%}\\n\\n\"\n",
    "        \n",
    "        if ground_truth_label is not None:\n",
    "            info_text += f\"âœ… Ground Truth: {gt_class_name} (Class {ground_truth_label})\\n\"\n",
    "            info_text += f\"âœ“ Prediction {'CORRECT' if gt_correct else 'INCORRECT'}\\n\\n\"\n",
    "        \n",
    "        info_text += \"COMPONENT ANALYSIS\\n\"\n",
    "        info_text += \"-\" * 40 + \"\\n\"\n",
    "        for comp, imp in zip(components, importances):\n",
    "            info_text += f\"â€¢ {comp}: {imp:.3f} \"\n",
    "            if imp > 0.5:\n",
    "                info_text += \"ðŸ”¥ (High Impact)\\n\"\n",
    "            elif imp > 0.2:\n",
    "                info_text += \"âš¡ (Moderate Impact)\\n\"\n",
    "            else:\n",
    "                info_text += \"ðŸ’§ (Low Impact)\\n\"\n",
    "        \n",
    "        info_text += \"\\n\" + \"=\" * 60 + \"\\n\"\n",
    "        info_text += \"ðŸ’¡ Key Insights:\\n\"\n",
    "        if 'spectral_importance' in locals() and 'vit_importance' in locals() and 'cnn_importance' in locals():\n",
    "            if spectral_importance > vit_importance and spectral_importance > cnn_importance:\n",
    "                info_text += \"â€¢ Spectral preprocessing is MOST important\\n\"\n",
    "                info_text += \"â€¢ Color/frequency features are crucial for this disease\\n\"\n",
    "            elif vit_importance > spectral_importance and vit_importance > cnn_importance:\n",
    "                info_text += \"â€¢ ViT attention is MOST important\\n\"\n",
    "                info_text += \"â€¢ Global context and relationships matter most\\n\"\n",
    "            else:\n",
    "                info_text += \"â€¢ EfficientNet features are MOST important\\n\"\n",
    "                info_text += \"â€¢ Local texture and patterns are key indicators\\n\"\n",
    "        \n",
    "        ax8.text(0.02, 0.98, info_text, transform=ax8.transAxes,\n",
    "                fontsize=10, fontfamily='monospace', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))\n",
    "        \n",
    "        plt.suptitle(f'CAMDF-Net  - Component Importance Analysis: {image_name}', \n",
    "                    fontsize=16, fontweight='bold', y=0.98)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        save_dir = self.output_dir / 'component_importance'\n",
    "        save_dir.mkdir(exist_ok=True)\n",
    "        save_path = save_dir / f'{image_name}_component_importance.png'\n",
    "        plt.savefig(str(save_path), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"âœ… Component importance visualization saved to: {save_path}\")\n",
    "        \n",
    "        return {\n",
    "            'image_name': image_name,\n",
    "            'save_path': str(save_path),\n",
    "            'predicted_class': pred_class,\n",
    "            'predicted_class_name': pred_class_name,\n",
    "            'confidence': confidence,\n",
    "            'ground_truth': ground_truth_label,\n",
    "            'ground_truth_name': gt_class_name,\n",
    "            'component_importances': dict(zip(components, importances))\n",
    "        }\n",
    "    \n",
    "    def batch_component_analysis(self, dataloader, class_names, num_samples=5):\n",
    "        print(f\"\\nðŸ“Š Running Batch Component Analysis on {num_samples} samples...\")\n",
    "        \n",
    "        import pandas as pd\n",
    "        \n",
    "        results = []\n",
    "        all_importances = {'Spectral': [], 'ViT Attention': [], 'EfficientNet': []}\n",
    "        \n",
    "        for i, (images, masks, labels, original_sizes) in enumerate(dataloader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(self.device)\n",
    "            label = labels[0].item()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(images[0:1])\n",
    "                all_activations = self.model.get_all_activations()\n",
    "            \n",
    "            probs = F.softmax(outputs['logits'], dim=1).cpu().numpy()[0]\n",
    "            pred_class = int(np.argmax(probs))\n",
    "            confidence = float(probs[pred_class])\n",
    "            \n",
    "            spectral_image = outputs['spectral_image'].cpu().numpy()[0].transpose(1, 2, 0)\n",
    "            vit_attention = all_activations.get('vit_spatial', None)\n",
    "            cnn_features = all_activations.get('cnn_features_raw', None)\n",
    "            \n",
    "            spectral_imp = 0.0\n",
    "            if spectral_image is not None:\n",
    "                spectral_imp = float(np.abs(spectral_image).mean())\n",
    "            \n",
    "            vit_imp = 0.0\n",
    "            if vit_attention is not None:\n",
    "                vit_attn = vit_attention.squeeze().cpu().numpy()\n",
    "                if vit_attn.ndim == 3:\n",
    "                    vit_imp = float(vit_attn.mean())\n",
    "            \n",
    "            cnn_imp = 0.0\n",
    "            if cnn_features is not None:\n",
    "                cnn_feat = cnn_features.squeeze().cpu().numpy()\n",
    "                if cnn_feat.ndim == 3:\n",
    "                    cnn_imp = float(cnn_feat.mean())\n",
    "            \n",
    "            result = {\n",
    "                'sample_id': i,\n",
    "                'true_class': class_names[label],\n",
    "                'pred_class': class_names[pred_class],\n",
    "                'correct': (label == pred_class),\n",
    "                'confidence': confidence,\n",
    "                'spectral_importance': spectral_imp,\n",
    "                'vit_importance': vit_imp,\n",
    "                'efficientnet_importance': cnn_imp,\n",
    "                'dominant_component': max(['Spectral', 'ViT Attention', 'EfficientNet'], \n",
    "                                         key=lambda x: [spectral_imp, vit_imp, cnn_imp][['Spectral', 'ViT Attention', 'EfficientNet'].index(x)])\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            all_importances['Spectral'].append(spectral_imp)\n",
    "            all_importances['ViT Attention'].append(vit_imp)\n",
    "            all_importances['EfficientNet'].append(cnn_imp)\n",
    "            \n",
    "            print(f\"  Sample {i+1}: {class_names[label]} â†’ {class_names[pred_class]} \"\n",
    "                  f\"(âœ“{label == pred_class}) | \"\n",
    "                  f\"S:{spectral_imp:.3f} V:{vit_imp:.3f} E:{cnn_imp:.3f}\")\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        ax1 = axes[0, 0]\n",
    "        avg_importances = {comp: np.mean(vals) for comp, vals in all_importances.items()}\n",
    "        bars = ax1.bar(avg_importances.keys(), avg_importances.values(), \n",
    "                       color=['blue', 'red', 'green'], edgecolor='black', alpha=0.7)\n",
    "        ax1.set_title('Average Component Importance', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Importance Score', fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, val in zip(bars, avg_importances.values()):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., val + 0.01,\n",
    "                    f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        ax2 = axes[0, 1]\n",
    "        dominant_counts = df['dominant_component'].value_counts()\n",
    "        ax2.pie(dominant_counts.values, labels=dominant_counts.index,\n",
    "               colors=['blue', 'red', 'green'], autopct='%1.1f%%',\n",
    "               startangle=90, textprops={'fontsize': 10, 'fontweight': 'bold'})\n",
    "        ax2.set_title('Dominant Component Distribution', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        ax3 = axes[1, 0]\n",
    "        correct_df = df[df['correct']]\n",
    "        incorrect_df = df[~df['correct']]\n",
    "        \n",
    "        if not correct_df.empty:\n",
    "            correct_means = [\n",
    "                correct_df['spectral_importance'].mean(),\n",
    "                correct_df['vit_importance'].mean(),\n",
    "                correct_df['efficientnet_importance'].mean()\n",
    "            ]\n",
    "        else:\n",
    "            correct_means = [0, 0, 0]\n",
    "        \n",
    "        if not incorrect_df.empty:\n",
    "            incorrect_means = [\n",
    "                incorrect_df['spectral_importance'].mean(),\n",
    "                incorrect_df['vit_importance'].mean(),\n",
    "                incorrect_df['efficientnet_importance'].mean()\n",
    "            ]\n",
    "        else:\n",
    "            incorrect_means = [0, 0, 0]\n",
    "        \n",
    "        x = np.arange(len(avg_importances))\n",
    "        width = 0.35\n",
    "        ax3.bar(x - width/2, correct_means, width, label='Correct Predictions', \n",
    "               color=['lightblue', 'lightcoral', 'lightgreen'], edgecolor='black')\n",
    "        ax3.bar(x + width/2, incorrect_means, width, label='Incorrect Predictions',\n",
    "               color=['blue', 'red', 'green'], edgecolor='black', alpha=0.6)\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(list(avg_importances.keys()))\n",
    "        ax3.set_title('Importance by Prediction Accuracy', fontsize=13, fontweight='bold')\n",
    "        ax3.set_ylabel('Average Importance')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        ax4 = axes[1, 1]\n",
    "        corr_data = df[['spectral_importance', 'vit_importance', 'efficientnet_importance', 'confidence']]\n",
    "        corr_matrix = corr_data.corr()\n",
    "        im = ax4.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        ax4.set_xticks(range(len(corr_matrix.columns)))\n",
    "        ax4.set_yticks(range(len(corr_matrix.columns)))\n",
    "        ax4.set_xticklabels(corr_matrix.columns, rotation=45, ha='right')\n",
    "        ax4.set_yticklabels(corr_matrix.columns)\n",
    "        ax4.set_title('Correlation Matrix', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(len(corr_matrix.columns)):\n",
    "                ax4.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
    "                        ha='center', va='center', color='white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black',\n",
    "                        fontsize=10, fontweight='bold')\n",
    "        \n",
    "        plt.colorbar(im, ax=ax4, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.suptitle(f'CAMDF-Net  - Batch Component Analysis ({num_samples} samples)', \n",
    "                    fontsize=16, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        save_dir = self.output_dir / 'batch_analysis'\n",
    "        save_dir.mkdir(exist_ok=True)\n",
    "        save_path = save_dir / 'component_analysis_summary.png'\n",
    "        plt.savefig(str(save_path), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        \n",
    "        csv_path = save_dir / 'component_analysis_stats.csv'\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(f\"\\nâœ… Batch analysis saved to: {save_path}\")\n",
    "        print(f\"ðŸ“Š Statistics saved to: {csv_path}\")\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Summary Statistics:\")\n",
    "        print(f\"  â€¢ Average Spectral Importance: {avg_importances['Spectral']:.3f}\")\n",
    "        print(f\"  â€¢ Average ViT Importance: {avg_importances['ViT Attention']:.3f}\")\n",
    "        print(f\"  â€¢ Average EfficientNet Importance: {avg_importances['EfficientNet']:.3f}\")\n",
    "        print(f\"  â€¢ Most dominant component: {dominant_counts.idxmax()} ({dominant_counts.max()}/{num_samples} samples)\")\n",
    "        print(f\"  â€¢ Accuracy: {df['correct'].mean():.2%}\")\n",
    "        \n",
    "        return df, avg_importances, save_path\n",
    "    \n",
    "    def create_all_summary_visualizations(self, results: Dict[str, Any], class_names: List[str]):\n",
    "        print(\"\\nðŸ“Š Creating summary-level visualizations...\")\n",
    "        summary_dir = self.output_dir / 'summary'\n",
    "        curves_dir = summary_dir / 'curves'\n",
    "        matrices_dir = summary_dir / 'matrices'\n",
    "        for d in [summary_dir, curves_dir, matrices_dir]:\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        labels = results['labels']\n",
    "        preds = results['predictions']\n",
    "        probs = results['probabilities']\n",
    "        uncertainties = results['uncertainties']\n",
    "        \n",
    "        self._plot_confusion_matrix(labels, preds, class_names, matrices_dir)\n",
    "        self._plot_normalized_confusion_matrix(labels, preds, class_names, matrices_dir)\n",
    "        self._plot_roc_curves(labels, probs, class_names, curves_dir)\n",
    "        self._plot_precision_recall_curves(labels, probs, class_names, curves_dir)\n",
    "        self._plot_per_class_accuracy(labels, preds, class_names, summary_dir)\n",
    "        self._plot_per_class_f1(labels, preds, class_names, summary_dir)\n",
    "        self._plot_uncertainty_distribution(uncertainties, labels, preds, class_names, summary_dir)\n",
    "        self._plot_confidence_distribution(probs, labels, preds, summary_dir)\n",
    "        self._plot_radar_chart(results, class_names, summary_dir)\n",
    "        self._save_classification_report(labels, preds, class_names, summary_dir)\n",
    "        self._plot_prediction_error_analysis(labels, preds, probs, class_names, summary_dir)\n",
    "        print(\"âœ… All summary visualizations complete!\\n\")\n",
    "    \n",
    "    def _plot_confusion_matrix(self, labels, preds, class_names, folder):\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "        ax.set_title('Confusion Matrix', fontsize=16, fontweight='bold', pad=15)\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        n = len(class_names)\n",
    "        ax.set_xticks(range(n)); ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=9)\n",
    "        ax.set_yticklabels(class_names, fontsize=9)\n",
    "        ax.set_xlabel('Predicted', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('True', fontsize=13, fontweight='bold')\n",
    "        thresh = cm.max() / 2.0\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                ax.text(j, i, format(cm[i, j], 'd'), ha='center', va='center',\n",
    "                       color='white' if cm[i, j] > thresh else 'black', fontsize=11, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'confusion_matrix.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Confusion matrix saved\")\n",
    "    \n",
    "    def _plot_normalized_confusion_matrix(self, labels, preds, class_names, folder):\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        cm_norm = cm.astype('float') / (cm.sum(axis=1, keepdims=True) + 1e-8)\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(cm_norm, interpolation='nearest', cmap='YlOrRd', vmin=0, vmax=1)\n",
    "        ax.set_title('Normalized Confusion Matrix', fontsize=16, fontweight='bold', pad=15)\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        n = len(class_names)\n",
    "        ax.set_xticks(range(n)); ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=9)\n",
    "        ax.set_yticklabels(class_names, fontsize=9)\n",
    "        ax.set_xlabel('Predicted', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('True', fontsize=13, fontweight='bold')\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                ax.text(j, i, f'{cm_norm[i, j]:.2f}', ha='center', va='center',\n",
    "                       color='white' if cm_norm[i, j] > 0.5 else 'black', fontsize=11, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'confusion_matrix_normalized.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Normalized confusion matrix saved\")\n",
    "    \n",
    "    def _plot_roc_curves(self, labels, probs, class_names, folder):\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        n_classes = len(class_names)\n",
    "        y_bin = label_binarize(labels, classes=range(n_classes))\n",
    "        if y_bin.shape[1] == 1:\n",
    "            y_bin = np.hstack([1 - y_bin, y_bin])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, n_classes))\n",
    "        aucs = []\n",
    "        for i in range(n_classes):\n",
    "            fpr, tpr, _ = roc_curve(y_bin[:, i], probs[:, i])\n",
    "            roc_auc = np.trapz(tpr, fpr)\n",
    "            aucs.append(roc_auc)\n",
    "            ax.plot(fpr, tpr, color=colors[i], lw=2, label=f'{class_names[i]} (AUC={roc_auc:.3f})')\n",
    "        ax.plot([0, 1], [0, 1], 'k--', lw=1.5, alpha=0.5, label='Random')\n",
    "        ax.set_xlabel('False Positive Rate', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('True Positive Rate', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('ROC Curves (One-vs-Rest)', fontsize=16, fontweight='bold', pad=15)\n",
    "        ax.legend(loc='lower right', fontsize=9, framealpha=0.95)\n",
    "        ax.set_xlim([0, 1]); ax.set_ylim([0, 1.05])\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'roc_curves.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… ROC curves saved\")\n",
    "    \n",
    "    def _plot_precision_recall_curves(self, labels, probs, class_names, folder):\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        n_classes = len(class_names)\n",
    "        y_bin = label_binarize(labels, classes=range(n_classes))\n",
    "        if y_bin.shape[1] == 1:\n",
    "            y_bin = np.hstack([1 - y_bin, y_bin])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, n_classes))\n",
    "        for i in range(n_classes):\n",
    "            prec, rec, _ = precision_recall_curve(y_bin[:, i], probs[:, i])\n",
    "            ap = average_precision_score(y_bin[:, i], probs[:, i])\n",
    "            ax.plot(rec, prec, color=colors[i], lw=2, label=f'{class_names[i]} (AP={ap:.3f})')\n",
    "        ax.set_xlabel('Recall', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Precision', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('Precision-Recall Curves', fontsize=16, fontweight='bold', pad=15)\n",
    "        ax.legend(loc='lower left', fontsize=9, framealpha=0.95)\n",
    "        ax.set_xlim([0, 1]); ax.set_ylim([0, 1.05])\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'precision_recall_curves.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Precision-Recall curves saved\")\n",
    "    \n",
    "    def _plot_per_class_accuracy(self, labels, preds, class_names, folder):\n",
    "        n = len(class_names)\n",
    "        per_class_acc = []\n",
    "        for i in range(n):\n",
    "            mask = labels == i\n",
    "            if mask.sum() > 0:\n",
    "                per_class_acc.append(float((preds[mask] == i).sum()) / float(mask.sum()) * 100)\n",
    "            else:\n",
    "                per_class_acc.append(0.0)\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        bars = ax.bar(range(n), per_class_acc, color=plt.cm.Set3(np.linspace(0, 1, n)), edgecolor='black', alpha=0.85)\n",
    "        ax.set_xticks(range(n)); ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=10)\n",
    "        ax.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('Per-Class Accuracy', fontsize=16, fontweight='bold', pad=15)\n",
    "        ax.set_ylim([0, 110]); ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        for b, v in zip(bars, per_class_acc):\n",
    "            ax.text(b.get_x() + b.get_width()/2., b.get_height() + 1, f'{v:.1f}%',\n",
    "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        ax.axhline(y=np.mean(per_class_acc), color='red', linestyle='--', lw=2, label=f'Mean: {np.mean(per_class_acc):.1f}%')\n",
    "        ax.legend(fontsize=11)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'per_class_accuracy.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Per-class accuracy saved\")\n",
    "    \n",
    "    def _plot_per_class_f1(self, labels, preds, class_names, folder):\n",
    "        _, _, f1_per, _ = precision_recall_fscore_support(labels, preds, average=None, zero_division=0)\n",
    "        n = len(class_names)\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        bars = ax.bar(range(n), f1_per * 100, color=plt.cm.Pastel1(np.linspace(0, 1, n)), edgecolor='black', alpha=0.85)\n",
    "        ax.set_xticks(range(n)); ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=10)\n",
    "        ax.set_ylabel('F1-Score (%)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('Per-Class F1-Score', fontsize=16, fontweight='bold', pad=15)\n",
    "        ax.set_ylim([0, 110]); ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        for b, v in zip(bars, f1_per * 100):\n",
    "            ax.text(b.get_x() + b.get_width()/2., b.get_height() + 1, f'{v:.1f}%',\n",
    "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'per_class_f1.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Per-class F1 saved\")\n",
    "    \n",
    "    def _plot_uncertainty_distribution(self, uncertainties, labels, preds, class_names, folder):\n",
    "        unc_flat = uncertainties.flatten()\n",
    "        correct = (preds == labels)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        axes[0].hist(unc_flat, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        axes[0].set_title('Uncertainty Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xlabel('Uncertainty'); axes[0].set_ylabel('Count'); axes[0].grid(True, alpha=0.3)\n",
    "        if correct.sum() > 0:\n",
    "            axes[1].hist(unc_flat[correct], bins=30, color='green', alpha=0.6, label='Correct', edgecolor='black')\n",
    "        if (~correct).sum() > 0:\n",
    "            axes[1].hist(unc_flat[~correct], bins=30, color='red', alpha=0.6, label='Incorrect', edgecolor='black')\n",
    "        axes[1].set_title('Uncertainty: Correct vs Wrong', fontsize=12, fontweight='bold')\n",
    "        axes[1].legend(fontsize=10); axes[1].grid(True, alpha=0.3)\n",
    "        for i, cn in enumerate(class_names):\n",
    "            mask = labels == i\n",
    "            if mask.sum() > 0:\n",
    "                axes[2].hist(unc_flat[mask], bins=20, alpha=0.5, label=cn[:15])\n",
    "        axes[2].set_title('Uncertainty by Class', fontsize=12, fontweight='bold')\n",
    "        axes[2].legend(fontsize=8); axes[2].grid(True, alpha=0.3)\n",
    "        plt.suptitle('Model Uncertainty Analysis', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'uncertainty_analysis.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Uncertainty analysis saved\")\n",
    "    \n",
    "    def _plot_confidence_distribution(self, probs, labels, preds, folder):\n",
    "        max_probs = probs.max(axis=1)\n",
    "        correct = (preds == labels)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax1.hist(max_probs, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        ax1.set_title('Confidence Distribution', fontsize=12, fontweight='bold')\n",
    "        ax1.set_xlabel('Max Probability'); ax1.set_ylabel('Count'); ax1.grid(True, alpha=0.3)\n",
    "        ax1.axvline(x=0.5, color='red', linestyle='--', label='50% threshold'); ax1.legend()\n",
    "        bins_edges = np.linspace(0, 1, 11)\n",
    "        bin_accs, bin_confs = [], []\n",
    "        for lo, hi in zip(bins_edges[:-1], bins_edges[1:]):\n",
    "            mask = (max_probs >= lo) & (max_probs < hi)\n",
    "            if mask.sum() > 0:\n",
    "                bin_accs.append(float(correct[mask].mean()))\n",
    "                bin_confs.append(float(max_probs[mask].mean()))\n",
    "        if bin_confs:\n",
    "            ax2.bar(bin_confs, bin_accs, width=0.08, color='coral', edgecolor='black', alpha=0.7, label='Accuracy')\n",
    "            ax2.plot([0, 1], [0, 1], 'k--', lw=1.5, label='Perfect calibration')\n",
    "            ax2.set_xlabel('Mean Predicted Confidence'); ax2.set_ylabel('Fraction Correct')\n",
    "            ax2.set_title('Reliability Diagram', fontsize=12, fontweight='bold')\n",
    "            ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "            ax2.set_xlim([0, 1]); ax2.set_ylim([0, 1.05])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'confidence_calibration.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Confidence calibration saved\")\n",
    "    \n",
    "    def _plot_radar_chart(self, results, class_names, folder):\n",
    "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'IoU', 'Dice']\n",
    "        values = [results['accuracy']*100, results['precision']*100, results['recall']*100,\n",
    "                  results['f1_score']*100, results['iou']*100, results['dice']*100]\n",
    "        N = len(metrics)\n",
    "        angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\n",
    "        values_closed = values + [values[0]]\n",
    "        angles_closed = angles + [angles[0]]\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "        ax.fill(angles_closed, values_closed, color='steelblue', alpha=0.25)\n",
    "        ax.plot(angles_closed, values_closed, 'o-', color='steelblue', lw=2.5, markersize=8)\n",
    "        ax.set_xticks(angles); ax.set_xticklabels(metrics, fontsize=11, fontweight='bold')\n",
    "        ax.set_ylim(0, 105); ax.set_title('Performance Radar', fontsize=16, fontweight='bold', pad=20)\n",
    "        for angle, val, label in zip(angles, values, metrics):\n",
    "            ax.text(angle, val + 4, f'{val:.1f}%', ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'performance_radar.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Radar chart saved\")\n",
    "    \n",
    "    def _save_classification_report(self, labels, preds, class_names, folder):\n",
    "        from sklearn.metrics import classification_report\n",
    "        report = classification_report(labels, preds, target_names=class_names, zero_division=0)\n",
    "        with open(str(folder / 'classification_report.txt'), 'w') as f:\n",
    "            f.write(report)\n",
    "        fig, ax = plt.subplots(figsize=(12, max(4, len(class_names) * 0.6 + 2)))\n",
    "        ax.text(0.05, 0.95, report, transform=ax.transAxes, fontsize=11, verticalalignment='top',\n",
    "               fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "        ax.set_title('Classification Report', fontsize=14, fontweight='bold'); ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'classification_report.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Classification report saved\")\n",
    "    \n",
    "    def _plot_prediction_error_analysis(self, labels, preds, probs, class_names, folder):\n",
    "        wrong = labels != preds\n",
    "        if wrong.sum() == 0:\n",
    "            print(\"   âœ… No errors to analyze (perfect accuracy)\")\n",
    "            return\n",
    "        n = len(class_names)\n",
    "        error_matrix = np.zeros((n, n))\n",
    "        for t, p in zip(labels[wrong], preds[wrong]):\n",
    "            error_matrix[t, p] += 1\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        im = ax1.imshow(error_matrix, cmap='Reds')\n",
    "        ax1.set_xticks(range(n)); ax1.set_yticks(range(n))\n",
    "        ax1.set_xticklabels(class_names, rotation=45, ha='right', fontsize=9)\n",
    "        ax1.set_yticklabels(class_names, fontsize=9)\n",
    "        ax1.set_xlabel('Predicted'); ax1.set_ylabel('True')\n",
    "        ax1.set_title('Error Matrix (misclassifications only)', fontsize=12, fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax1, fraction=0.046, pad=0.04)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if error_matrix[i, j] > 0:\n",
    "                    ax1.text(j, i, f'{int(error_matrix[i, j])}', ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "        wrong_confs = probs[wrong].max(axis=1)\n",
    "        ax2.hist(wrong_confs, bins=30, color='salmon', edgecolor='darkred', alpha=0.7)\n",
    "        ax2.set_title('Confidence of Misclassifications', fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlabel('Confidence'); ax2.set_ylabel('Count'); ax2.grid(True, alpha=0.3)\n",
    "        ax2.axvline(x=np.mean(wrong_confs), color='black', linestyle='--', label=f'Mean: {np.mean(wrong_confs):.3f}')\n",
    "        ax2.legend()\n",
    "        plt.suptitle('Prediction Error Analysis', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folder / 'error_analysis.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"   âœ… Error analysis saved\")\n",
    "    \n",
    "    def _visualize_vit_headwise(self, image_tensor, folders, image_name, original_size):\n",
    "        print(f\"      ðŸ§  Visualizing ViT head-wise attention...\")\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        head_attns = self.model.get_vit_self_attention(image_tensor, return_all_heads=True)\n",
    "        for layer_name, heads in head_attns.items():\n",
    "            if isinstance(heads, dict):\n",
    "                for head_name, attn_map in heads.items():\n",
    "                    head_idx = int(head_name.split('_')[-1]) if head_name.split('_')[-1].isdigit() else 0\n",
    "                    hf = folders['4b_vit_headwise'] / f'head_{head_idx:02d}'\n",
    "                    hf.mkdir(exist_ok=True)\n",
    "                    am = attn_map.squeeze().cpu().float().numpy()\n",
    "                    if am.ndim == 2:\n",
    "                        ar = self._safe_resize_2d(am, tw)\n",
    "                        plt.imsave(str(hf / f'{layer_name}_{head_name}.png'), self._normalize_for_display(ar), cmap='magma')\n",
    "                fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "                axes = axes.flatten()\n",
    "                for idx, (hn, am) in enumerate(heads.items()):\n",
    "                    if idx >= 12: break\n",
    "                    a = am.squeeze().cpu().float().numpy()\n",
    "                    if a.ndim == 2:\n",
    "                        axes[idx].imshow(self._normalize_for_display(self._safe_resize_2d(a, tw)), cmap='magma')\n",
    "                    axes[idx].set_title(hn, fontsize=8, fontweight='bold'); axes[idx].axis('off')\n",
    "                for idx in range(len(heads), 12): axes[idx].axis('off')\n",
    "                plt.suptitle(f'ViT Self-Attention Heads: {layer_name}', fontsize=12, fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(str(folders['4b_vit_headwise'] / f'{image_name}_{layer_name}_all_heads.png'),\n",
    "                           dpi=300, bbox_inches='tight', facecolor='white')\n",
    "                plt.close()\n",
    "    \n",
    "    def _visualize_segmentation_layers(self, all_activations, folders, image_name, original_size):\n",
    "        print(f\"      ðŸŽ­ Visualizing segmentation layers...\")\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        seg_keys = sorted([k for k in all_activations.keys() if k.startswith('seg_layer_')])\n",
    "        for aname in seg_keys:\n",
    "            t = all_activations[aname]\n",
    "            if t is None: continue\n",
    "            layer_num = aname.split('_')[-1]\n",
    "            lf = folders['6d_segmentation_layers'] / f'layer_{int(layer_num):03d}'\n",
    "            lf.mkdir(exist_ok=True)\n",
    "            self.visualize_activation_layer(t, aname, lf, original_size, 'summer')\n",
    "        mask_keys = [k for k in all_activations.keys() if any(w in k.lower() for w in ['mask_logits', 'refined_mask', 'final_mask', 'gated_x'])]\n",
    "        if mask_keys:\n",
    "            cols = min(4, len(mask_keys))\n",
    "            rows = (len(mask_keys) + cols - 1) // cols\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "            if rows == 1 and cols == 1: axes = np.array([[axes]])\n",
    "            elif rows == 1: axes = axes.reshape(1, -1)\n",
    "            elif cols == 1: axes = axes.reshape(-1, 1)\n",
    "            for idx, mn in enumerate(mask_keys):\n",
    "                r, c = idx // cols, idx % cols\n",
    "                mt = t.squeeze().cpu().float().numpy()\n",
    "                if mt.ndim == 3: mt = mt.mean(axis=0)\n",
    "                elif mt.ndim < 2: axes[r, c].text(0.5, 0.5, f'{mn}', ha='center', va='center'); axes[r, c].axis('off'); continue\n",
    "                mr = self._safe_resize_2d(mt, tw)\n",
    "                axes[r, c].imshow(self._normalize_for_display(mr), cmap='bone')\n",
    "                axes[r, c].set_title(mn[:25], fontsize=9, fontweight='bold'); axes[r, c].axis('off')\n",
    "            for idx in range(len(mask_keys), rows * cols): axes[idx // cols, idx % cols].axis('off')\n",
    "            plt.suptitle(f'Mask Generation Progression: {image_name}', fontsize=12, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folders['6c_mask_generation'] / f'{image_name}_mask_progression.png'),\n",
    "                       dpi=300, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "    \n",
    "    def _visualize_classifier_features(self, all_activations, folders, image_name):\n",
    "        print(f\"      ðŸ“Š Visualizing classifier features...\")\n",
    "        cls_keys = [k for k in all_activations.keys() if any(w in k.lower() for w in ['classifier', 'cls_logits', 'uncertainty'])]\n",
    "        for aname in cls_keys:\n",
    "            t = all_activations[aname]\n",
    "            if t is None: continue\n",
    "            anp = t.squeeze().cpu().float().numpy()\n",
    "            if anp.ndim >= 1:\n",
    "                fig, ax = plt.subplots(figsize=(10, 5))\n",
    "                if anp.ndim == 1:\n",
    "                    bars = ax.bar(range(len(anp)), anp, color='coral', edgecolor='black', alpha=0.7)\n",
    "                    for b, v in zip(bars, anp):\n",
    "                        ax.text(b.get_x() + b.get_width()/2., b.get_height() + 0.01, f'{v:.3f}',\n",
    "                               ha='center', fontsize=9)\n",
    "                else:\n",
    "                    ax.imshow(self._normalize_for_display(anp), cmap='spring', aspect='auto')\n",
    "                ax.set_title(f'{aname}', fontsize=11, fontweight='bold'); ax.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(str(folders['7a_classifier_features'] / f'{image_name}_{aname}.png'),\n",
    "                           dpi=300, bbox_inches='tight', facecolor='white')\n",
    "                plt.close()\n",
    "    \n",
    "    def _create_feature_comparison_grid(self, all_activations, folders, image_name, original_size):\n",
    "        print(f\"      ðŸ“ Creating feature comparison grid...\")\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        feat_keys = [k for k in all_activations.keys() if any(w in k.lower() for w in ['cnn_features', 'vit_spatial', 'fused_features', 'cnn_aligned'])]\n",
    "        feat_keys = [k for k in feat_keys if all_activations[k] is not None]\n",
    "        if not feat_keys: return\n",
    "        fig, axes = plt.subplots(1, len(feat_keys), figsize=(5 * len(feat_keys), 5))\n",
    "        if len(feat_keys) == 1: axes = [axes]\n",
    "        cmaps = ['plasma', 'magma', 'coolwarm', 'viridis']\n",
    "        for idx, fn in enumerate(feat_keys):\n",
    "            t = all_activations[fn].squeeze().cpu().float().numpy()\n",
    "            if t.ndim == 3: t = t.mean(axis=0)\n",
    "            elif t.ndim != 2: axes[idx].text(0.5, 0.5, fn[:20], ha='center', va='center'); axes[idx].axis('off'); continue\n",
    "            axes[idx].imshow(self._normalize_for_display(self._safe_resize_2d(t, tw)), cmap=cmaps[idx % len(cmaps)])\n",
    "            axes[idx].set_title(fn[:25], fontsize=10, fontweight='bold'); axes[idx].axis('off')\n",
    "        plt.suptitle(f'Feature Comparison: {image_name}', fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folders['10b_feature_grids'] / f'{image_name}_feature_comparison.png'),\n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    def _create_attention_grid(self, all_activations, folders, image_name, original_size):\n",
    "        print(f\"      ðŸ” Creating attention comparison grid...\")\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        attn_keys = [k for k in all_activations.keys() if 'attention' in k.lower() and all_activations[k] is not None]\n",
    "        if not attn_keys: return\n",
    "        n = min(6, len(attn_keys))\n",
    "        cols = min(3, n); rows = (n + cols - 1) // cols\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))\n",
    "        if rows == 1 and cols == 1: axes = np.array([[axes]])\n",
    "        elif rows == 1: axes = axes.reshape(1, -1)\n",
    "        elif cols == 1: axes = axes.reshape(-1, 1)\n",
    "        for idx, an in enumerate(attn_keys[:n]):\n",
    "            r, c = idx // cols, idx % cols\n",
    "            t = all_activations[an].squeeze().cpu().float().numpy()\n",
    "            if t.ndim == 3: t = t.mean(axis=0)\n",
    "            elif t.ndim != 2: axes[r, c].text(0.5, 0.5, an[:20], ha='center', va='center'); axes[r, c].axis('off'); continue\n",
    "            axes[r, c].imshow(self._normalize_for_display(self._safe_resize_2d(t, tw)), cmap='hot')\n",
    "            axes[r, c].set_title(an[:25], fontsize=9, fontweight='bold'); axes[r, c].axis('off')\n",
    "        for idx in range(n, rows * cols): axes[idx // cols, idx % cols].axis('off')\n",
    "        plt.suptitle(f'Attention Comparison: {image_name}', fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folders['10c_attention_grids'] / f'{image_name}_attention_grid.png'),\n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    def _save_gradient_stats(self, gradients, folders, image_name):\n",
    "        if not gradients: return\n",
    "        print(f\"      ðŸ“‰ Saving gradient statistics...\")\n",
    "        stats = {}\n",
    "        for n, g in gradients.items():\n",
    "            if g is not None:\n",
    "                gnp = g.cpu().float().numpy()\n",
    "                stats[n] = {'mean': float(np.mean(gnp)), 'std': float(np.std(gnp)),\n",
    "                           'min': float(np.min(gnp)), 'max': float(np.max(gnp)),\n",
    "                           'l2_norm': float(np.sqrt(np.sum(gnp**2))), 'shape': list(gnp.shape)}\n",
    "        with open(str(folders['11b_gradient_stats'] / f'{image_name}_gradient_stats.json'), 'w') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        src = folders['3c_cnn_gradients'] / f'{image_name}_gradient_analysis.png'\n",
    "        dst = folders['12b_gradient_flow'] / f'{image_name}_gradient_flow.png'\n",
    "        if src.exists():\n",
    "            import shutil\n",
    "            shutil.copy2(str(src), str(dst))\n",
    "    \n",
    "    def _save_per_image_metrics(self, image_name, class_name, confidence, severity, folders):\n",
    "        metrics = {'image': image_name, 'class': class_name, 'confidence': confidence, 'severity': severity}\n",
    "        with open(str(folders['11c_performance_metrics'] / f'{image_name}_metrics.json'), 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        text = (f\"Image: {image_name}\\nPredicted: {class_name}\\nConfidence: {confidence:.2%}\\n\"\n",
    "                f\"Severity: {severity['severity_level']}\\nAffected: {severity['affected_percentage']:.1f}%\\n\"\n",
    "                f\"Lesions: {severity['num_lesions']}\")\n",
    "        ax.text(0.1, 0.5, text, fontsize=13, va='center', fontfamily='monospace',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))\n",
    "        ax.set_title('Per-Image Metrics', fontsize=14, fontweight='bold'); ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folders['11c_performance_metrics'] / f'{image_name}_metrics.png'),\n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    def _save_severity_visualization(self, pred_mask_uint8, severity, folders, image_name):\n",
    "        print(f\"      âš•ï¸  Saving severity visualization...\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax1.imshow(pred_mask_uint8, cmap='hot')\n",
    "        ax1.set_title(f'Disease Map: {severity[\"severity_level\"]}', fontsize=12, fontweight='bold'); ax1.axis('off')\n",
    "        levels = ['Healthy', 'Minimal', 'Mild', 'Moderate', 'Severe', 'Critical']\n",
    "        colors_sev = ['#2ecc71', '#27ae60', '#f1c40f', '#e67e22', '#e74c3c', '#c0392b']\n",
    "        current_idx = levels.index(severity['severity_level']) if severity['severity_level'] in levels else 0\n",
    "        bar_colors = ['lightgray'] * len(levels)\n",
    "        bar_colors[current_idx] = colors_sev[current_idx]\n",
    "        ax2.barh(range(len(levels)), [100/len(levels)] * len(levels), color=bar_colors, edgecolor='black', alpha=0.7)\n",
    "        ax2.set_yticks(range(len(levels))); ax2.set_yticklabels(levels, fontsize=11)\n",
    "        ax2.set_title(f'Severity: {severity[\"affected_percentage\"]:.1f}% affected', fontsize=12, fontweight='bold')\n",
    "        ax2.axhline(y=current_idx, color=colors_sev[current_idx], lw=3, linestyle='--')\n",
    "        ax2.grid(True, alpha=0.3, axis='x')\n",
    "        plt.suptitle(f'Disease Severity: {image_name}', fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folders['11d_disease_severity'] / f'{image_name}_severity.png'),\n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        with open(str(folders['11d_disease_severity'] / f'{image_name}_severity.json'), 'w') as f:\n",
    "            json.dump(severity, f, indent=2)\n",
    "    \n",
    "    def _save_model_state_snapshot(self, folders, image_name):\n",
    "        summary = {\n",
    "            'model_name': self.config.model.name,\n",
    "            'num_parameters': sum(p.numel() for p in self.model.parameters()),\n",
    "            'num_trainable': sum(p.numel() for p in self.model.parameters() if p.requires_grad),\n",
    "            'hidden_dim': self.model.hidden_dim,\n",
    "            'num_heads': self.model.num_heads,\n",
    "            'num_activations_stored': len(self.model.activations),\n",
    "            'activation_keys': list(self.model.activations.keys()),\n",
    "        }\n",
    "        with open(str(folders['12c_model_states'] / f'{image_name}_model_state.json'), 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "    \n",
    "    def _save_normalized_input(self, image_tensor, folders, image_name, original_size):\n",
    "        inp = image_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "        inp_norm = self._normalize_for_display(inp)\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        inp_resized = cv2.resize(inp_norm, tw, interpolation=cv2.INTER_CUBIC)\n",
    "        plt.imsave(str(folders['2b_normalized'] / f'{image_name}_normalized.png'), np.clip(inp_resized, 0, 1))\n",
    "        ch_names = ['Red (norm)', 'Green (norm)', 'Blue (norm)']\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        for i in range(3):\n",
    "            ch = inp[:, :, i]\n",
    "            ch_r = cv2.resize(ch, tw, interpolation=cv2.INTER_CUBIC)\n",
    "            axes[i].imshow(ch_r, cmap='gray'); axes[i].set_title(ch_names[i], fontsize=11, fontweight='bold'); axes[i].axis('off')\n",
    "        plt.suptitle(f'Normalized Input Channels: {image_name}', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(folders['2b_normalized'] / f'{image_name}_channels.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    def _save_fused_feature_viz(self, all_activations, folders, image_name, original_size):\n",
    "        tw = (int(original_size[0]), int(original_size[1]))\n",
    "        fused = all_activations.get('fused_features')\n",
    "        if fused is None: return\n",
    "        fnp = fused.squeeze().cpu().float().numpy()\n",
    "        if fnp.ndim == 3:\n",
    "            nc = min(fnp.shape[0], 16)\n",
    "            cols, rows = 4, (nc + 3) // 4\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3))\n",
    "            if rows == 1 and cols == 1: axes = np.array([[axes]])\n",
    "            elif rows == 1: axes = axes.reshape(1, -1)\n",
    "            elif cols == 1: axes = axes.reshape(-1, 1)\n",
    "            for idx in range(nc):\n",
    "                r, c = idx // cols, idx % cols\n",
    "                ch = self._normalize_for_display(self._safe_resize_2d(fnp[idx], tw))\n",
    "                axes[r, c].imshow(ch, cmap='coolwarm'); axes[r, c].set_title(f'Fused Ch {idx}', fontsize=8, fontweight='bold'); axes[r, c].axis('off')\n",
    "            for idx in range(nc, rows * cols): axes[idx // cols, idx % cols].axis('off')\n",
    "            plt.suptitle(f'Fused Features: {image_name}', fontsize=12, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folders['5b_fused_features'] / f'{image_name}_fused_grid.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            mean_fused = fnp.mean(axis=0)\n",
    "            plt.imsave(str(folders['5b_fused_features'] / f'{image_name}_fused_mean.png'),\n",
    "                       self._normalize_for_display(self._safe_resize_2d(mean_fused, tw)), cmap='coolwarm')\n",
    "    \n",
    "    def _save_cnn_vit_statistics(self, all_activations, folders, image_name):\n",
    "        for prefix, folder_key in [('cnn', '3d_cnn_statistics'), ('vit', '4e_vit_statistics')]:\n",
    "            keys = [k for k in all_activations.keys() if prefix in k.lower() and all_activations[k] is not None]\n",
    "            if not keys: continue\n",
    "            stats_list = []\n",
    "            for k in keys:\n",
    "                t = all_activations[k].cpu().float()\n",
    "                stats_list.append({'name': k, 'shape': list(t.shape), 'mean': float(t.mean()),\n",
    "                                   'std': float(t.std()), 'min': float(t.min()), 'max': float(t.max()),\n",
    "                                   'numel': int(t.numel())})\n",
    "            with open(str(folders[folder_key] / f'{image_name}_{prefix}_stats.json'), 'w') as f:\n",
    "                json.dump(stats_list, f, indent=2)\n",
    "            fig, ax = plt.subplots(figsize=(12, 5))\n",
    "            names = [s['name'][:20] for s in stats_list]\n",
    "            means = [s['mean'] for s in stats_list]\n",
    "            stds = [s['std'] for s in stats_list]\n",
    "            ax.bar(range(len(names)), means, yerr=stds, color='steelblue' if prefix == 'cnn' else 'mediumpurple',\n",
    "                   edgecolor='black', alpha=0.7, capsize=3)\n",
    "            ax.set_xticks(range(len(names))); ax.set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "            ax.set_title(f'{prefix.upper()} Activation Statistics: {image_name}', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Mean Â± Std'); ax.grid(True, alpha=0.3, axis='y')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str(folders[folder_key] / f'{image_name}_{prefix}_stats.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "    \n",
    "    def _save_metadata_extras(self, folders, image_name, config, class_name, confidence, severity, saved_paths):\n",
    "        from dataclasses import asdict\n",
    "        with open(str(folders['13a_configurations'] / f'{image_name}_config.json'), 'w') as f:\n",
    "            json.dump(asdict(config), f, indent=2)\n",
    "        pred_data = {'image': image_name, 'class': class_name, 'confidence': confidence, 'severity': severity}\n",
    "        with open(str(folders['13b_predictions'] / f'{image_name}_prediction.json'), 'w') as f:\n",
    "            json.dump(pred_data, f, indent=2)\n",
    "        report = (f\"CAMDF-Net  Analysis Report\\n{'='*40}\\n\"\n",
    "                  f\"Image: {image_name}\\nPredicted: {class_name} ({confidence:.2%})\\n\"\n",
    "                  f\"Severity: {severity['severity_level']} ({severity['affected_percentage']:.1f}%)\\n\"\n",
    "                  f\"Lesions: {severity['num_lesions']}\\n\"\n",
    "                  f\"Recommendation: {self.generate_recommendation(severity, confidence)}\\n\"\n",
    "                  f\"Generated: {datetime.datetime.now().isoformat()}\\n\")\n",
    "        with open(str(folders['13c_analysis_reports'] / f'{image_name}_report.txt'), 'w') as f:\n",
    "            f.write(report)\n",
    "        log = {'image': image_name, 'timestamp': datetime.datetime.now().isoformat(),\n",
    "               'files_generated': list(saved_paths.keys()),\n",
    "               'total_visualizations': self.count_visualizations(folders['root'])}\n",
    "        with open(str(folders['13d_visualization_logs'] / f'{image_name}_viz_log.json'), 'w') as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "\n",
    "    def visualize_all_activations_and_features(self, image_path, class_names,\n",
    "                                              ground_truth_mask=None,\n",
    "                                              ground_truth_original_size=None):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ðŸŒŸ VISUALIZATION FOR: {Path(image_path).name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        original_image = Image.open(image_path).convert('RGB')\n",
    "        original_size = original_image.size\n",
    "        original_img_np = np.array(original_image)\n",
    "        image_name = Path(image_path).stem\n",
    "        \n",
    "        print(f\"    ðŸ“ Creating folder structure...\")\n",
    "        folders = self.create_comprehensive_image_folder_structure(image_name)\n",
    "        saved_paths = {'image_name': image_name}\n",
    "        \n",
    "        plt.imsave(str(folders['0_original'] / f'{image_name}_original.png'), original_img_np)\n",
    "        saved_paths['original'] = str(folders['0_original'] / f'{image_name}_original.png')\n",
    "        \n",
    "        if ground_truth_mask is not None:\n",
    "            gmu = (ground_truth_mask * 255).astype(np.uint8) if ground_truth_mask.max() <= 1 else ground_truth_mask.astype(np.uint8)\n",
    "            plt.imsave(str(folders['8b_ground_truth'] / f'{image_name}_gt.png'), gmu, cmap='gray')\n",
    "            saved_paths['ground_truth'] = str(folders['8b_ground_truth'] / f'{image_name}_gt.png')\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((self.config.dataset.image_size, self.config.dataset.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image_tensor = transform(original_image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        print(f\"    ðŸ” Forward pass...\")\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "            all_activations = self.model.get_all_activations()\n",
    "        \n",
    "        inp = image_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "        inp = np.clip(inp * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]), 0, 1)\n",
    "        inp_resized = np.clip(cv2.resize(inp, original_size, interpolation=cv2.INTER_CUBIC), 0, 1)\n",
    "        plt.imsave(str(folders['1_inputs'] / f'{image_name}_input.png'), inp_resized)\n",
    "        saved_paths['model_input'] = str(folders['1_inputs'] / f'{image_name}_input.png')\n",
    "        \n",
    "        probs = F.softmax(outputs['logits'], dim=1).cpu().numpy()[0]\n",
    "        pred_class = int(np.argmax(probs))\n",
    "        confidence = float(probs[pred_class])\n",
    "        class_name = class_names[pred_class]\n",
    "        \n",
    "        pred_mask = torch.sigmoid(outputs['mask']).cpu().numpy()[0, 0]\n",
    "        pred_mask_resized = cv2.resize(pred_mask, original_size, interpolation=cv2.INTER_LINEAR)\n",
    "        pred_mask_uint8 = (pred_mask_resized * 255).astype(np.uint8)\n",
    "        \n",
    "        plt.imsave(str(folders['8a_predicted_masks'] / f'{image_name}_pred_mask.png'), pred_mask_uint8, cmap='gray')\n",
    "        saved_paths['predicted_mask'] = str(folders['8a_predicted_masks'] / f'{image_name}_pred_mask.png')\n",
    "        \n",
    "        mc = cv2.applyColorMap(pred_mask_uint8, cv2.COLORMAP_JET)\n",
    "        overlay = cv2.addWeighted(original_img_np, 0.6, mc, 0.4, 0)\n",
    "        plt.imsave(str(folders['8c_overlays'] / f'{image_name}_overlay.png'), overlay)\n",
    "        saved_paths['overlay'] = str(folders['8c_overlays'] / f'{image_name}_overlay.png')\n",
    "        \n",
    "        print(f\"    ðŸŽ¨ Generating ALL activation visualizations...\")\n",
    "        self.create_comprehensive_activation_report(all_activations, folders, image_name, original_size)\n",
    "        \n",
    "        all_gradients = self.model.get_all_gradients()\n",
    "        if all_gradients:\n",
    "            print(f\"    ðŸ“‰ Gradient flow...\")\n",
    "            self.visualize_gradient_flow(all_gradients, folders, image_name)\n",
    "            self._save_gradient_stats(all_gradients, folders, image_name)\n",
    "        \n",
    "        print(f\"    âš•ï¸  Severity analysis...\")\n",
    "        severity = self.compute_disease_severity(pred_mask_uint8)\n",
    "        \n",
    "        print(f\"    ðŸ§  Populating all per-image visualization folders...\")\n",
    "        self._visualize_vit_headwise(image_tensor, folders, image_name, original_size)\n",
    "        self._visualize_segmentation_layers(all_activations, folders, image_name, original_size)\n",
    "        self._visualize_classifier_features(all_activations, folders, image_name)\n",
    "        self._create_feature_comparison_grid(all_activations, folders, image_name, original_size)\n",
    "        self._create_attention_grid(all_activations, folders, image_name, original_size)\n",
    "        self._save_per_image_metrics(image_name, class_name, confidence, severity, folders)\n",
    "        self._save_severity_visualization(pred_mask_uint8, severity, folders, image_name)\n",
    "        self._save_model_state_snapshot(folders, image_name)\n",
    "        self._save_normalized_input(image_tensor, folders, image_name, original_size)\n",
    "        self._save_fused_feature_viz(all_activations, folders, image_name, original_size)\n",
    "        self._save_cnn_vit_statistics(all_activations, folders, image_name)\n",
    "        \n",
    "        metadata = {\n",
    "            'image_name': image_name, 'original_size': {'w': original_size[0], 'h': original_size[1]},\n",
    "            'predicted_class': pred_class, 'class_name': class_name, 'confidence': confidence,\n",
    "            'probabilities': probs.tolist(),\n",
    "            'uncertainty': float(outputs['uncertainty'].cpu().numpy()[0, 0]),\n",
    "            'severity': severity, 'num_activations': len(all_activations),\n",
    "            'activation_names': list(all_activations.keys()),\n",
    "            'timestamp': datetime.datetime.now().isoformat(), 'version': 'CAMDF-Net '\n",
    "        }\n",
    "        with open(str(folders['13_metadata'] / f'{image_name}_metadata.json'), 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        saved_paths['metadata'] = str(folders['13_metadata'] / f'{image_name}_metadata.json')\n",
    "        \n",
    "        print(f\"    ðŸŽ¨ Creating ULTIMATE grid...\")\n",
    "        ug = self.create_ultimate_comprehensive_grid(\n",
    "            image_name, original_img_np, pred_mask_uint8, ground_truth_mask,\n",
    "            all_activations, pred_class, class_name, confidence, severity,\n",
    "            folders, original_size)\n",
    "        saved_paths['ultimate_grid'] = ug\n",
    "        \n",
    "        self._save_metadata_extras(folders, image_name, self.config, class_name, confidence, severity, saved_paths)\n",
    "        \n",
    "        self.generate_visualization_summary(folders, image_name, saved_paths)\n",
    "        total_viz = self.count_visualizations(folders['root'])\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"âœ… COMPLETE! Folder: {folders['root']}\")\n",
    "        print(f\"ðŸ“Š Visualizations: {total_viz} | ðŸŽ¯ {class_name} ({confidence:.2%})\")\n",
    "        print(f\"âš•ï¸  {severity['severity_level']} ({severity['affected_percentage']:.1f}%) | ðŸ“ˆ {len(all_activations)} activations\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        return saved_paths\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "def main(config_path: Optional[str] = None):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CAMDF-NET   - ULTIMATE VISUALIZATION PIPELINE\".center(80))\n",
    "    print(\"No Resizing in Evaluation | All Activations Saved | Beautiful Visuals\".center(80))\n",
    "    print(\"Component Importance Analysis | Spectral + ViT + EfficientNet\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    if config_path and Path(config_path).exists():\n",
    "        config = CAMDFNetConfig.from_yaml(config_path)\n",
    "        print(f\"âœ…    Loaded configuration from: {config_path}\")\n",
    "    else:\n",
    "        config = CAMDFNetConfig()\n",
    "        print(\"âœ…    Using default configuration\")\n",
    "    \n",
    "    config.dataset.preserve_original_size_eval = True\n",
    "    config.system.save_all_intermediates = True\n",
    "    config.model.save_all_activations = True\n",
    "    \n",
    "    torch.manual_seed(config.system.seed)\n",
    "    np.random.seed(config.system.seed)\n",
    "    \n",
    "    config_save_path = Path(config.system.log_dir) / 'config_used.yaml'\n",
    "    config_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    config.to_yaml(str(config_save_path))\n",
    "    print(f\"âœ…    Configuration saved to: {config_save_path}\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"PHASE 1: TRAINING\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    trainer = CAMDFNetTrainer(config)\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PHASE 2: COMPREHENSIVE EVALUATION\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    best_ckpt = Path(config.system.checkpoint_dir) / 'best.pth'\n",
    "    if best_ckpt.exists():\n",
    "        print(f\"ðŸ¤–     Loading best model from: {best_ckpt}\")\n",
    "        ckpt = torch.load(best_ckpt, map_location=trainer.device, weights_only=False)\n",
    "        trainer.model.load_state_dict(ckpt['model_state_dict'])\n",
    "        print(\"âœ…    Best model loaded\\n\")\n",
    "    else:\n",
    "        print(\"âš ï¸    Best checkpoint not found, using current model\\n\")\n",
    "    \n",
    "    evaluator = CAMDFNetEvaluator(trainer.model, config)\n",
    "    class_names = trainer.train_loader.dataset.dataset.classes\n",
    "\n",
    "    print(\"Running comprehensive evaluation...\")\n",
    "    results = evaluator.evaluate(trainer.test_loader)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EVALUATION RESULTS\".center(80))\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Accuracy:  {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n",
    "    print(f\"  Precision: {results['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {results['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results['f1_score']:.4f}\")\n",
    "    print(f\"  IoU:       {results['iou']:.4f}\")\n",
    "    print(f\"  Dice:      {results['dice']:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Generating summary-level visualizations...\")\n",
    "    evaluator.create_all_summary_visualizations(results, class_names)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PHASE 3: PER-IMAGE ANALYSIS\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    test_dataset = trainer.test_loader.dataset\n",
    "    base_dataset = test_dataset.dataset\n",
    "    subset_indices = test_dataset.indices\n",
    "    \n",
    "    sample_count = 0\n",
    "    processed_classes = set()\n",
    "    \n",
    "    print(f\"ðŸš€ Processing sample images...\\n\")\n",
    "    \n",
    "    for subset_idx in range(len(test_dataset)):\n",
    "        if sample_count >= 16:\n",
    "            break\n",
    "            \n",
    "        img_tensor, gt_mask_tensor, label, original_size = test_dataset[subset_idx]\n",
    "        \n",
    "        if label in processed_classes:\n",
    "            continue\n",
    "\n",
    "        base_idx = subset_indices[subset_idx]\n",
    "        img_path = base_dataset.samples[base_idx][0]\n",
    "        \n",
    "        print(f\"ðŸ“¸    Image {sample_count + 1}: {Path(img_path).name}\")\n",
    "        print(f\"      Class: {class_names[label]}, Size: {original_size}\")\n",
    "        \n",
    "        gt_mask_np = gt_mask_tensor.squeeze(0).numpy()\n",
    "        \n",
    "        saved_paths = evaluator.visualize_all_activations_and_features(\n",
    "            img_path, class_names,\n",
    "            ground_truth_mask=gt_mask_np,\n",
    "            ground_truth_original_size=original_size\n",
    "        )\n",
    "            \n",
    "        print(f\"      âœ…    Saved to: per_image_results/{saved_paths['image_name']}/\\n\")\n",
    "            \n",
    "        processed_classes.add(label)\n",
    "        sample_count += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PHASE 4: COMPONENT IMPORTANCE ANALYSIS\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(\"ðŸ”¬ Analyzing component importance for sample images...\\n\")\n",
    "    \n",
    "    sample_count = 0\n",
    "    component_results = []\n",
    "    \n",
    "    for subset_idx in range(len(test_dataset)):\n",
    "        if sample_count >= 4:\n",
    "            break\n",
    "        \n",
    "        img_tensor, gt_mask_tensor, label, original_size = test_dataset[subset_idx]\n",
    "        base_idx = subset_indices[subset_idx]\n",
    "        img_path = base_dataset.samples[base_idx][0]\n",
    "        \n",
    "        print(f\"ðŸ“Š Analyzing: {Path(img_path).name}\")\n",
    "        print(f\"  Ground Truth: {class_names[label]}\")\n",
    "        \n",
    "        result = evaluator.visualize_component_importance(\n",
    "            img_path, \n",
    "            class_names, \n",
    "            ground_truth_label=label\n",
    "        )\n",
    "        \n",
    "        print(f\"  Predicted: {result['predicted_class_name']} ({result['confidence']:.2%})\")\n",
    "        print(f\"  Component Importances:\")\n",
    "        for comp, imp in result['component_importances'].items():\n",
    "            print(f\"    â€¢ {comp}: {imp:.3f}\")\n",
    "        print()\n",
    "        \n",
    "        component_results.append(result)\n",
    "        sample_count += 1\n",
    "    \n",
    "    print(\"ðŸ“ˆ Running batch component analysis...\")\n",
    "    import pandas as pd\n",
    "    df, avg_importances, analysis_path = evaluator.batch_component_analysis(\n",
    "        trainer.test_loader, \n",
    "        class_names, \n",
    "        num_samples=max(10, len(trainer.test_loader))\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PIPELINE COMPLETE - CAMDF-NET \".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(\"ðŸ“¦     Output Structure:\")\n",
    "    print(f\"  ðŸ“Š  Summary:           {config.system.output_dir}/summary/\")\n",
    "    print(f\"  ðŸ“  Per-Image:        {config.system.output_dir}/per_image_results/\")\n",
    "    print(f\"  ðŸ”¬  Component Analysis:{config.system.output_dir}/component_importance/\")\n",
    "    print(f\"  ðŸ“ˆ  Batch Analysis:   {config.system.output_dir}/batch_analysis/\")\n",
    "    print(f\"  ðŸ’¾  Checkpoints:      {config.system.checkpoint_dir}\")\n",
    "    print(f\"  ðŸ“ˆ  Training Logs:    {config.system.log_dir}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”¬  Component Importance Summary:\")\n",
    "    print(f\"  â€¢ Spectral Component:     {avg_importances['Spectral']:.3f}\")\n",
    "    print(f\"  â€¢ ViT Attention:          {avg_importances['ViT Attention']:.3f}\")\n",
    "    print(f\"  â€¢ EfficientNet Features:  {avg_importances['EfficientNet']:.3f}\")\n",
    "    \n",
    "    if 'Spectral' in avg_importances and 'ViT Attention' in avg_importances and 'EfficientNet' in avg_importances:\n",
    "        most_important = max(avg_importances, key=avg_importances.get)\n",
    "        print(f\"  â€¢ Most Important:        {most_important}\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡  Key Insights:\")\n",
    "        if most_important == 'Spectral':\n",
    "            print(f\"  â€¢ Spectral preprocessing is CRUCIAL for cotton disease detection\")\n",
    "            print(f\"  â€¢ Color and frequency features are key indicators\")\n",
    "            print(f\"  â€¢ Consider enhancing spectral analysis further\")\n",
    "        elif most_important == 'ViT Attention':\n",
    "            print(f\"  â€¢ Global context (ViT attention) is most important\")\n",
    "            print(f\"  â€¢ Disease patterns and spatial relationships matter\")\n",
    "            print(f\"  â€¢ Consider increasing ViT capacity\")\n",
    "        else:\n",
    "            print(f\"  â€¢ Local texture features (EfficientNet) are most important\")\n",
    "            print(f\"  â€¢ Disease spots and local patterns are key\")\n",
    "            print(f\"  â€¢ Consider deeper CNN backbone\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š  Performance Summary:\")\n",
    "    print(f\"  â€¢ Accuracy:  {results['accuracy']*100:.2f}%\")\n",
    "    print(f\"  â€¢ F1-Score:  {results['f1_score']*100:.2f}%\")\n",
    "    print(f\"  â€¢ IoU:       {results['iou']*100:.2f}%\")\n",
    "    print(f\"  â€¢ Dice:      {results['dice']*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸŽ‰ ALL DONE! Results ready for analysis.\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 891340,
     "sourceId": 1512654,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2742184,
     "sourceId": 5127834,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 277323,
     "sourceId": 658267,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
